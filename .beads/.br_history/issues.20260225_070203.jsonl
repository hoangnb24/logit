{"id":"bd-10h","title":"Implement SQLite writer with batched inserts and transaction handling","description":"Write normalized records to SQLite efficiently and safely using batched inserts and explicit transaction boundaries.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:56.738008Z","created_by":"themrb","updated_at":"2026-02-25T07:00:30.216820Z","compaction_level":0,"original_size":0,"labels":["logit","sqlite","writer"],"dependencies":[{"issue_id":"bd-10h","depends_on_id":"bd-1kq","type":"parent-child","created_at":"2026-02-25T06:58:56.739226Z","created_by":"themrb"},{"issue_id":"bd-10h","depends_on_id":"bd-1xy","type":"blocks","created_at":"2026-02-25T07:00:30.182328Z","created_by":"themrb"},{"issue_id":"bd-10h","depends_on_id":"bd-9eb","type":"blocks","created_at":"2026-02-25T07:00:30.216805Z","created_by":"themrb"}],"comments":[{"id":65,"issue_id":"bd-10h","author":"HoangNB","text":"Goal:\nWrite normalized records to SQLite efficiently and safely using batched inserts and explicit transaction boundaries.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:56Z"}]}
{"id":"bd-10m","title":"Parse Codex history.jsonl and merge as auxiliary prompts","description":"Ingest Codex history prompts as auxiliary events while avoiding duplicate amplification against rollout data.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:30.040640Z","created_by":"themrb","updated_at":"2026-02-25T07:00:28.239660Z","compaction_level":0,"original_size":0,"labels":["adapter","codex","history","logit"],"dependencies":[{"issue_id":"bd-10m","depends_on_id":"bd-2j8","type":"blocks","created_at":"2026-02-25T07:00:28.239645Z","created_by":"themrb"},{"issue_id":"bd-10m","depends_on_id":"bd-398","type":"parent-child","created_at":"2026-02-25T06:58:30.042131Z","created_by":"themrb"}],"comments":[{"id":43,"issue_id":"bd-10m","author":"HoangNB","text":"Goal:\nIngest Codex history prompts as auxiliary events while avoiding duplicate amplification against rollout data.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-12a","title":"Index Gemini protobuf conversation artifacts as snapshot-only metadata in v1","description":"Record protobuf conversation files for visibility without attempting protobuf decode in v1 normalization.","status":"open","priority":3,"issue_type":"task","created_at":"2026-02-25T06:58:30.552681Z","created_by":"themrb","updated_at":"2026-02-25T07:00:28.843446Z","compaction_level":0,"original_size":0,"labels":["adapter","gemini","logit","pb"],"dependencies":[{"issue_id":"bd-12a","depends_on_id":"bd-2lr","type":"blocks","created_at":"2026-02-25T07:00:28.843430Z","created_by":"themrb"},{"issue_id":"bd-12a","depends_on_id":"bd-38g","type":"parent-child","created_at":"2026-02-25T06:58:30.554619Z","created_by":"themrb"}],"comments":[{"id":52,"issue_id":"bd-12a","author":"HoangNB","text":"Goal:\nRecord protobuf conversation files for visibility without attempting protobuf decode in v1 normalization.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-13b","title":"Implement error taxonomy and exit code contract","description":"Guarantee meaningful failures and machine-usable exit statuses for automation and CI usage.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:57:38.531335Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.818704Z","compaction_level":0,"original_size":0,"labels":["cli","logit","reliability"],"dependencies":[{"issue_id":"bd-13b","depends_on_id":"bd-182","type":"blocks","created_at":"2026-02-25T07:00:26.818689Z","created_by":"themrb"},{"issue_id":"bd-13b","depends_on_id":"bd-3i0","type":"blocks","created_at":"2026-02-25T07:00:26.787291Z","created_by":"themrb"},{"issue_id":"bd-13b","depends_on_id":"bd-soe","type":"parent-child","created_at":"2026-02-25T06:57:38.532843Z","created_by":"themrb"}],"comments":[{"id":24,"issue_id":"bd-13b","author":"HoangNB","text":"Goal:\nGuarantee meaningful failures and machine-usable exit statuses for automation and CI usage.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:38Z"}]}
{"id":"bd-13n","title":"Implement schema validation against generated agentlog.v1 schema","description":"Validate normalized JSONL records against the generated schema artifact and report line-level failures.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:56.915375Z","created_by":"themrb","updated_at":"2026-02-25T07:00:30.449752Z","compaction_level":0,"original_size":0,"labels":["logit","schema","validate"],"dependencies":[{"issue_id":"bd-13n","depends_on_id":"bd-2uh","type":"blocks","created_at":"2026-02-25T07:00:30.449736Z","created_by":"themrb"},{"issue_id":"bd-13n","depends_on_id":"bd-343","type":"blocks","created_at":"2026-02-25T07:00:30.417351Z","created_by":"themrb"},{"issue_id":"bd-13n","depends_on_id":"bd-u6d","type":"parent-child","created_at":"2026-02-25T06:58:56.916768Z","created_by":"themrb"}],"comments":[{"id":68,"issue_id":"bd-13n","author":"HoangNB","text":"Goal:\nValidate normalized JSONL records against the generated schema artifact and report line-level failures.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:56Z"}]}
{"id":"bd-13y","title":"Epic: Test Matrix, Fixtures, and End-to-End Acceptance","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-25T06:56:29.544614Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.446213Z","compaction_level":0,"original_size":0,"labels":["epic","logit","test"],"dependencies":[{"issue_id":"bd-13y","depends_on_id":"bd-165","type":"blocks","created_at":"2026-02-25T07:00:26.393627Z","created_by":"themrb"},{"issue_id":"bd-13y","depends_on_id":"bd-1d7","type":"parent-child","created_at":"2026-02-25T06:56:29.545765Z","created_by":"themrb"},{"issue_id":"bd-13y","depends_on_id":"bd-1kq","type":"blocks","created_at":"2026-02-25T07:00:26.420963Z","created_by":"themrb"},{"issue_id":"bd-13y","depends_on_id":"bd-1re","type":"blocks","created_at":"2026-02-25T07:00:26.222237Z","created_by":"themrb"},{"issue_id":"bd-13y","depends_on_id":"bd-38g","type":"blocks","created_at":"2026-02-25T07:00:26.319694Z","created_by":"themrb"},{"issue_id":"bd-13y","depends_on_id":"bd-398","type":"blocks","created_at":"2026-02-25T07:00:26.272544Z","created_by":"themrb"},{"issue_id":"bd-13y","depends_on_id":"bd-39z","type":"blocks","created_at":"2026-02-25T07:00:26.246628Z","created_by":"themrb"},{"issue_id":"bd-13y","depends_on_id":"bd-3hw","type":"blocks","created_at":"2026-02-25T07:00:26.344788Z","created_by":"themrb"},{"issue_id":"bd-13y","depends_on_id":"bd-lb0","type":"blocks","created_at":"2026-02-25T07:00:26.296097Z","created_by":"themrb"},{"issue_id":"bd-13y","depends_on_id":"bd-u6d","type":"blocks","created_at":"2026-02-25T07:00:26.446193Z","created_by":"themrb"},{"issue_id":"bd-13y","depends_on_id":"bd-xdl","type":"blocks","created_at":"2026-02-25T07:00:26.369639Z","created_by":"themrb"}],"comments":[{"id":14,"issue_id":"bd-13y","author":"HoangNB","text":"Intent:\nEstablish high-confidence quality gates across unit, adapter, integration, and end-to-end layers.\n\nScope:\n- fixture corpus by agent\n- deterministic tests for mappings and edge cases\n- acceptance scenarios matching product goals\n","created_at":"2026-02-25T06:56:30Z"}]}
{"id":"bd-149","title":"Add snapshot integrity checks (counts, parseability, deterministic sampling)","description":"Ensure snapshot outputs are internally consistent and reproducible across runs.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:57:39.197272Z","created_by":"themrb","updated_at":"2026-02-25T07:00:27.457738Z","compaction_level":0,"original_size":0,"labels":["logit","quality","snapshot"],"dependencies":[{"issue_id":"bd-149","depends_on_id":"bd-1sk","type":"blocks","created_at":"2026-02-25T07:00:27.457723Z","created_by":"themrb"},{"issue_id":"bd-149","depends_on_id":"bd-39z","type":"parent-child","created_at":"2026-02-25T06:57:39.198666Z","created_by":"themrb"}],"comments":[{"id":35,"issue_id":"bd-149","author":"HoangNB","text":"Goal:\nEnsure snapshot outputs are internally consistent and reproducible across runs.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:39Z"}]}
{"id":"bd-165","title":"Epic: Normalization Engine and agentlog.v1 Artifacts","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-25T06:56:29.451453Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.155078Z","compaction_level":0,"original_size":0,"labels":["epic","logit","normalize"],"dependencies":[{"issue_id":"bd-165","depends_on_id":"bd-1d7","type":"parent-child","created_at":"2026-02-25T06:56:29.452537Z","created_by":"themrb"},{"issue_id":"bd-165","depends_on_id":"bd-280","type":"blocks","created_at":"2026-02-25T07:00:26.131984Z","created_by":"themrb"},{"issue_id":"bd-165","depends_on_id":"bd-soe","type":"blocks","created_at":"2026-02-25T07:00:26.155060Z","created_by":"themrb"}],"comments":[{"id":11,"issue_id":"bd-165","author":"HoangNB","text":"Intent:\nBuild the core normalization pipeline and artifact emitter for agentlog.v1.\n\nScope:\n- canonical event struct + schema file\n- dedupe, ordering, timestamp normalization\n- JSONL writer and stats generation\n\nReasoning:\nThis is the semantic core of the project and all adapters converge here.\n","created_at":"2026-02-25T06:56:29Z"}]}
{"id":"bd-16z","title":"Parse Gemini messages array content variants","description":"Normalize Gemini message array elements including heterogeneous content shapes.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:34.491901Z","created_by":"themrb","updated_at":"2026-02-25T06:59:34.524892Z","compaction_level":0,"original_size":0,"labels":["gemini","logit","subtask"],"dependencies":[{"issue_id":"bd-16z","depends_on_id":"bd-1k0","type":"parent-child","created_at":"2026-02-25T06:59:34.493601Z","created_by":"themrb"}],"comments":[{"id":95,"issue_id":"bd-16z","author":"HoangNB","text":"Subtask intent:\nNormalize Gemini message array elements including heterogeneous content shapes.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:34Z"}]}
{"id":"bd-182","title":"Implement runtime config resolution (paths, home expansion, outdir defaults)","description":"Resolve runtime paths deterministically, including default output location and override behaviors.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:38.467354Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.754720Z","compaction_level":0,"original_size":0,"labels":["cli","config","logit"],"dependencies":[{"issue_id":"bd-182","depends_on_id":"bd-386","type":"blocks","created_at":"2026-02-25T07:00:26.754704Z","created_by":"themrb"},{"issue_id":"bd-182","depends_on_id":"bd-soe","type":"parent-child","created_at":"2026-02-25T06:57:38.468683Z","created_by":"themrb"}],"comments":[{"id":23,"issue_id":"bd-182","author":"HoangNB","text":"Goal:\nResolve runtime paths deterministically, including default output location and override behaviors.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:38Z"}]}
{"id":"bd-1a1","title":"Amp adapter edge-case handling, blob limits, and mapping verification","description":"Consolidate Amp-specific size constraints, malformed artifact handling, and mapping verification cases.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:30.900517Z","created_by":"themrb","updated_at":"2026-02-25T07:00:29.368142Z","compaction_level":0,"original_size":0,"labels":["adapter","amp","logit","quality"],"dependencies":[{"issue_id":"bd-1a1","depends_on_id":"bd-1vv","type":"blocks","created_at":"2026-02-25T07:00:29.368121Z","created_by":"themrb"},{"issue_id":"bd-1a1","depends_on_id":"bd-25d","type":"blocks","created_at":"2026-02-25T07:00:29.336140Z","created_by":"themrb"},{"issue_id":"bd-1a1","depends_on_id":"bd-2pj","type":"blocks","created_at":"2026-02-25T07:00:29.269029Z","created_by":"themrb"},{"issue_id":"bd-1a1","depends_on_id":"bd-34x","type":"blocks","created_at":"2026-02-25T07:00:29.304369Z","created_by":"themrb"},{"issue_id":"bd-1a1","depends_on_id":"bd-3hw","type":"parent-child","created_at":"2026-02-25T06:58:30.902233Z","created_by":"themrb"}],"comments":[{"id":58,"issue_id":"bd-1a1","author":"HoangNB","text":"Goal:\nConsolidate Amp-specific size constraints, malformed artifact handling, and mapping verification cases.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-1ac","title":"Implement invariant catalog executor for semantic checks","description":"Run non-schema semantic checks and emit structured diagnostic findings.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:35.215058Z","created_by":"themrb","updated_at":"2026-02-25T06:59:35.244852Z","compaction_level":0,"original_size":0,"labels":["logit","subtask","validate"],"dependencies":[{"issue_id":"bd-1ac","depends_on_id":"bd-26k","type":"parent-child","created_at":"2026-02-25T06:59:35.216568Z","created_by":"themrb"}],"comments":[{"id":107,"issue_id":"bd-1ac","author":"HoangNB","text":"Subtask intent:\nRun non-schema semantic checks and emit structured diagnostic findings.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:35Z"}]}
{"id":"bd-1c4","title":"Implement OpenCode part-to-message join index by IDs","description":"Build deterministic join index keyed by message and session IDs for content enrichment.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:34.744991Z","created_by":"themrb","updated_at":"2026-02-25T06:59:34.784418Z","compaction_level":0,"original_size":0,"labels":["logit","opencode","subtask"],"dependencies":[{"issue_id":"bd-1c4","depends_on_id":"bd-32e","type":"parent-child","created_at":"2026-02-25T06:59:34.746357Z","created_by":"themrb"}],"comments":[{"id":99,"issue_id":"bd-1c4","author":"HoangNB","text":"Subtask intent:\nBuild deterministic join index keyed by message and session IDs for content enrichment.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:34Z"}]}
{"id":"bd-1d7","title":"Program: Build logit Rust CLI for multi-agent local log intelligence","status":"open","priority":0,"issue_type":"epic","created_at":"2026-02-25T06:55:51.578372Z","created_by":"themrb","updated_at":"2026-02-25T07:01:42.015923Z","compaction_level":0,"original_size":0,"labels":["logit","planning","program"],"comments":[{"id":1,"issue_id":"bd-1d7","author":"HoangNB","text":"Background:\nThis program turns ad-hoc, tool-specific local agent logs into a consistent, queryable operational dataset.\nWe are standardizing around a Rust CLI (`logit`) with deterministic output contracts and repeatable ingestion.\n\nWhy this exists:\n- We currently have heterogeneous local traces across Codex, Claude, Gemini, Amp, and OpenCode.\n- Valuable context is fragmented, difficult to inspect, and hard to compare across tools.\n- We need a durable normalization pipeline so future analysis, debugging, and automation are reliable.\n\nNorth-star outcomes:\n1) One canonical normalized event contract (agentlog.v1)\n2) Reproducible snapshot + normalize + validate workflow\n3) Optional SQLite mirror for local analytics\n4) Self-documenting execution and dependency graph in beads\n\nImplementation philosophy:\n- Non-destructive and read-only with respect to source logs\n- Deterministic transforms; minimal hidden behavior\n- Explicit acceptance criteria per work item\n- Strong observability (stats, reports, validation artifacts)\n\nProgram-level done criteria:\n- All child epics complete and integrated.\n- `logit normalize` generates valid schema + JSONL from all 5 adapters.\n- `logit validate` can certify outputs.\n- Evidence-based test matrix and docs are complete.\n","created_at":"2026-02-25T06:55:51Z"},{"id":115,"issue_id":"bd-1d7","author":"HoangNB","text":"Execution map (recommended order):\n\nPhase 1: Foundation contracts and CLI shell\n- A1-A5, C1-C5\n- Rationale: lock canonical semantics and command behavior before parser implementation.\n\nPhase 2: Discovery and snapshot observability\n- D1-D5, S1-S5 (+ subtasks)\n- Rationale: establish visibility into real source shape drift before deep adapter work.\n\nPhase 3: Adapter implementation (parallelizable)\n- Codex: X1-X4\n- Claude: CL1-CL4\n- Gemini: G1-G4\n- Amp: AM1-AM5\n- OpenCode: O1-O5\n- Rationale: each adapter can proceed in parallel once canonical contracts are fixed.\n\nPhase 4: Core normalize path\n- N1-N6 (+ subtasks)\n- Rationale: fan-in orchestration should start after adapter maturity to minimize churn.\n\nPhase 5: Optional mirror and quality gates\n- Q1-Q4, V1-V4\n- Rationale: parity and validation depend on stable normalized outputs.\n\nPhase 6: Tests, docs, and release readiness\n- T1-T6, DOC1-DOC5 (+ subtasks)\n- Rationale: ensure reliable adoption and future maintainability.\n\nRisk notes:\n- Highest structural risk: OpenCode part/message join integrity and Amp blob handling.\n- Highest semantic risk: dedupe and timestamp ordering consistency.\n- Highest operational risk: accidentally leaking sensitive text in snapshot outputs.\n\nOperator intent:\n- This bead graph is intentionally more granular than strictly necessary to reduce implicit decisions.\n- Future contributors should be able to execute work without additional oral context.\n","created_at":"2026-02-25T07:01:17Z"},{"id":116,"issue_id":"bd-1d7","author":"HoangNB","text":"Graph index and structure summary:\n\nTotals:\n- 114 issues total\n- 15 epics (including root program)\n- 99 task-level items (tasks + subtasks)\n- 302 dependency edges\n- 0 dependency cycles\n\nTop-level epic index:\n- bd-280  Architecture, Contracts, and Safety Defaults\n- bd-soe  CLI Skeleton, Command Surface, and Runtime Plumbing\n- bd-1re  Discovery and Source Inventory\n- bd-39z  Snapshot Pipeline\n- bd-398  Codex Adapter\n- bd-lb0  Claude Adapter\n- bd-38g  Gemini Adapter\n- bd-3hw  Amp Adapter\n- bd-xdl  OpenCode Adapter\n- bd-165  Normalization Engine and agentlog.v1 Artifacts\n- bd-1kq  Optional SQLite Mirror\n- bd-u6d  Validation and Consistency Reports\n- bd-13y  Test Matrix, Fixtures, and End-to-End Acceptance\n- bd-5k4  Documentation and Release Readiness\n\nExecution starting points (ready now):\n- Root program + Architecture + CLI foundation tasks\n- These were intentionally left ready to begin incremental execution immediately.\n\nNote:\nIssue IDs in this workspace currently use the `bd-*` format even when managed via `br`; this is expected for this configured beads workspace.\n","created_at":"2026-02-25T07:01:42Z"}]}
{"id":"bd-1dk","title":"Emit discovery artifacts (sources.json, zsh_history_usage.json)","description":"Persist discovery evidence so ingestion decisions are transparent and debuggable.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:57:38.906140Z","created_by":"themrb","updated_at":"2026-02-25T07:00:27.182844Z","compaction_level":0,"original_size":0,"labels":["artifacts","discovery","logit"],"dependencies":[{"issue_id":"bd-1dk","depends_on_id":"bd-1re","type":"parent-child","created_at":"2026-02-25T06:57:38.907485Z","created_by":"themrb"},{"issue_id":"bd-1dk","depends_on_id":"bd-3ui","type":"blocks","created_at":"2026-02-25T07:00:27.182829Z","created_by":"themrb"}],"comments":[{"id":30,"issue_id":"bd-1dk","author":"HoangNB","text":"Goal:\nPersist discovery evidence so ingestion decisions are transparent and debuggable.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:38Z"}]}
{"id":"bd-1fy","title":"Draft release checklist template with required evidence links","description":"Create release checklist format that references validation/test artifacts and readiness gates.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:35.659272Z","created_by":"themrb","updated_at":"2026-02-25T06:59:35.692005Z","compaction_level":0,"original_size":0,"labels":["docs","logit","subtask"],"dependencies":[{"issue_id":"bd-1fy","depends_on_id":"bd-8o6","type":"parent-child","created_at":"2026-02-25T06:59:35.660730Z","created_by":"themrb"}],"comments":[{"id":113,"issue_id":"bd-1fy","author":"HoangNB","text":"Subtask intent:\nCreate release checklist format that references validation/test artifacts and readiness gates.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:35Z"}]}
{"id":"bd-1gt","title":"Define privacy defaults: snapshot redaction rules vs normalize full-text policy","description":"Establish explicit data-handling defaults so operators know exactly what is redacted, retained, or transformed.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:38.180073Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.536964Z","compaction_level":0,"original_size":0,"labels":["architecture","logit","safety"],"dependencies":[{"issue_id":"bd-1gt","depends_on_id":"bd-280","type":"parent-child","created_at":"2026-02-25T06:57:38.181461Z","created_by":"themrb"},{"issue_id":"bd-1gt","depends_on_id":"bd-nn2","type":"blocks","created_at":"2026-02-25T07:00:26.536948Z","created_by":"themrb"}],"comments":[{"id":18,"issue_id":"bd-1gt","author":"HoangNB","text":"Goal:\nEstablish explicit data-handling defaults so operators know exactly what is redacted, retained, or transformed.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:38Z"}]}
{"id":"bd-1h0","title":"Map Claude user-assistant-system-progress event families","description":"Implement deterministic mapping for core Claude event families into canonical types.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:34.370039Z","created_by":"themrb","updated_at":"2026-02-25T06:59:34.402905Z","compaction_level":0,"original_size":0,"labels":["claude","logit","subtask"],"dependencies":[{"issue_id":"bd-1h0","depends_on_id":"bd-2vc","type":"parent-child","created_at":"2026-02-25T06:59:34.371734Z","created_by":"themrb"}],"comments":[{"id":93,"issue_id":"bd-1h0","author":"HoangNB","text":"Subtask intent:\nImplement deterministic mapping for core Claude event families into canonical types.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:34Z"}]}
{"id":"bd-1k0","title":"Parse Gemini chat session JSON files and message arrays","description":"Map Gemini chat session message arrays into canonical events while preserving session context metadata.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:30.500062Z","created_by":"themrb","updated_at":"2026-02-25T07:00:28.810077Z","compaction_level":0,"original_size":0,"labels":["adapter","chats","gemini","logit"],"dependencies":[{"issue_id":"bd-1k0","depends_on_id":"bd-38g","type":"parent-child","created_at":"2026-02-25T06:58:30.501867Z","created_by":"themrb"},{"issue_id":"bd-1k0","depends_on_id":"bd-9yb","type":"blocks","created_at":"2026-02-25T07:00:28.810062Z","created_by":"themrb"}],"comments":[{"id":51,"issue_id":"bd-1k0","author":"HoangNB","text":"Goal:\nMap Gemini chat session message arrays into canonical events while preserving session context metadata.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-1kq","title":"Epic: Optional SQLite Mirror","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-25T06:56:29.481796Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.176919Z","compaction_level":0,"original_size":0,"labels":["epic","logit","sqlite"],"dependencies":[{"issue_id":"bd-1kq","depends_on_id":"bd-165","type":"blocks","created_at":"2026-02-25T07:00:26.176906Z","created_by":"themrb"},{"issue_id":"bd-1kq","depends_on_id":"bd-1d7","type":"parent-child","created_at":"2026-02-25T06:56:29.483029Z","created_by":"themrb"}],"comments":[{"id":12,"issue_id":"bd-1kq","author":"HoangNB","text":"Intent:\nProvide optional SQLite mirror for local analytics without changing primary JSONL contract.\n\nScope:\n- database schema aligned with canonical event model\n- efficient inserts and indexes\n- parity checks against emitted JSONL\n","created_at":"2026-02-25T06:56:30Z"}]}
{"id":"bd-1ly","title":"Implement text and content extraction helpers plus derived excerpt generation","description":"Standardize content extraction from diverse payload shapes while preserving full text where available.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:39.380957Z","created_by":"themrb","updated_at":"2026-02-25T07:00:27.691459Z","compaction_level":0,"original_size":0,"labels":["content","logit","normalize"],"dependencies":[{"issue_id":"bd-1ly","depends_on_id":"bd-165","type":"parent-child","created_at":"2026-02-25T06:57:39.382777Z","created_by":"themrb"},{"issue_id":"bd-1ly","depends_on_id":"bd-1gt","type":"blocks","created_at":"2026-02-25T07:00:27.691443Z","created_by":"themrb"},{"issue_id":"bd-1ly","depends_on_id":"bd-nn2","type":"blocks","created_at":"2026-02-25T07:00:27.657820Z","created_by":"themrb"}],"comments":[{"id":38,"issue_id":"bd-1ly","author":"HoangNB","text":"Goal:\nStandardize content extraction from diverse payload shapes while preserving full text where available.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:39Z"}]}
{"id":"bd-1mo","title":"Define timestamp normalization hierarchy and ordering contract","description":"Specify how ISO/epoch variants are normalized, how null timestamps are handled, and how total order is produced.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:38.233922Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.572890Z","compaction_level":0,"original_size":0,"labels":["architecture","logit","time"],"dependencies":[{"issue_id":"bd-1mo","depends_on_id":"bd-280","type":"parent-child","created_at":"2026-02-25T06:57:38.235438Z","created_by":"themrb"},{"issue_id":"bd-1mo","depends_on_id":"bd-nn2","type":"blocks","created_at":"2026-02-25T07:00:26.572873Z","created_by":"themrb"}],"comments":[{"id":19,"issue_id":"bd-1mo","author":"HoangNB","text":"Goal:\nSpecify how ISO/epoch variants are normalized, how null timestamps are handled, and how total order is produced.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:38Z"}]}
{"id":"bd-1oy","title":"Implement dedupe key computation with canonical hashing","description":"Compute primary and fallback dedupe keys to avoid duplicate inflation.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:34.873002Z","created_by":"themrb","updated_at":"2026-02-25T06:59:34.908443Z","compaction_level":0,"original_size":0,"labels":["logit","normalize","subtask"],"dependencies":[{"issue_id":"bd-1oy","depends_on_id":"bd-9ej","type":"parent-child","created_at":"2026-02-25T06:59:34.874966Z","created_by":"themrb"}],"comments":[{"id":101,"issue_id":"bd-1oy","author":"HoangNB","text":"Subtask intent:\nCompute primary and fallback dedupe keys to avoid duplicate inflation.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:34Z"}]}
{"id":"bd-1qi","title":"Implement sampled-hash parity checker between JSONL and SQLite","description":"Compare sampled record hashes across sinks to detect field-level divergence.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:35.160896Z","created_by":"themrb","updated_at":"2026-02-25T07:00:30.382818Z","compaction_level":0,"original_size":0,"labels":["logit","sqlite","subtask"],"dependencies":[{"issue_id":"bd-1qi","depends_on_id":"bd-mt5","type":"blocks","created_at":"2026-02-25T07:00:30.382802Z","created_by":"themrb"},{"issue_id":"bd-1qi","depends_on_id":"bd-ohq","type":"parent-child","created_at":"2026-02-25T06:59:35.162160Z","created_by":"themrb"}],"comments":[{"id":106,"issue_id":"bd-1qi","author":"HoangNB","text":"Subtask intent:\nCompare sampled record hashes across sinks to detect field-level divergence.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:35Z"}]}
{"id":"bd-1re","title":"Epic: Discovery and Source Inventory (including zsh history prioritization)","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-25T06:56:29.207118Z","created_by":"themrb","updated_at":"2026-02-25T07:00:25.936754Z","compaction_level":0,"original_size":0,"labels":["discovery","epic","logit"],"dependencies":[{"issue_id":"bd-1re","depends_on_id":"bd-1d7","type":"parent-child","created_at":"2026-02-25T06:56:29.208387Z","created_by":"themrb"},{"issue_id":"bd-1re","depends_on_id":"bd-280","type":"blocks","created_at":"2026-02-25T07:00:25.936737Z","created_by":"themrb"},{"issue_id":"bd-1re","depends_on_id":"bd-soe","type":"blocks","created_at":"2026-02-25T07:00:25.902717Z","created_by":"themrb"}],"comments":[{"id":4,"issue_id":"bd-1re","author":"HoangNB","text":"Intent:\nImplement deterministic source discovery across all supported agents with transparent prioritization.\n\nScope:\n- well-known path discovery\n- source classification (jsonl/json/log/binary)\n- optional influence from shell history (`~/.zsh_history`)\n\nReasoning:\nDiscovery quality directly controls coverage and trust in downstream normalization.\n","created_at":"2026-02-25T06:56:29Z"}]}
{"id":"bd-1sk","title":"Write snapshot artifacts per agent (index.json, samples.jsonl)","description":"Persist snapshot outputs in stable locations so they can be reviewed and versioned reliably.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:57:39.130996Z","created_by":"themrb","updated_at":"2026-02-25T07:00:27.425492Z","compaction_level":0,"original_size":0,"labels":["artifacts","logit","snapshot"],"dependencies":[{"issue_id":"bd-1sk","depends_on_id":"bd-39z","type":"parent-child","created_at":"2026-02-25T06:57:39.132645Z","created_by":"themrb"},{"issue_id":"bd-1sk","depends_on_id":"bd-3ew","type":"blocks","created_at":"2026-02-25T07:00:27.425477Z","created_by":"themrb"},{"issue_id":"bd-1sk","depends_on_id":"bd-3jn","type":"blocks","created_at":"2026-02-25T07:00:27.396569Z","created_by":"themrb"},{"issue_id":"bd-1sk","depends_on_id":"bd-jbe","type":"blocks","created_at":"2026-02-25T07:00:27.367734Z","created_by":"themrb"}],"comments":[{"id":34,"issue_id":"bd-1sk","author":"HoangNB","text":"Goal:\nPersist snapshot outputs in stable locations so they can be reviewed and versioned reliably.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:39Z"}]}
{"id":"bd-1vv","title":"Parse Amp file-change artifacts and map tool/file telemetry safely","description":"Extract useful tool and file-change telemetry from Amp artifacts while truncating large before/after blobs safely.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:30.843353Z","created_by":"themrb","updated_at":"2026-02-25T07:00:29.237190Z","compaction_level":0,"original_size":0,"labels":["adapter","amp","filechanges","logit"],"dependencies":[{"issue_id":"bd-1vv","depends_on_id":"bd-1gt","type":"blocks","created_at":"2026-02-25T07:00:29.237174Z","created_by":"themrb"},{"issue_id":"bd-1vv","depends_on_id":"bd-2pj","type":"blocks","created_at":"2026-02-25T07:00:29.203675Z","created_by":"themrb"},{"issue_id":"bd-1vv","depends_on_id":"bd-3hw","type":"parent-child","created_at":"2026-02-25T06:58:30.844855Z","created_by":"themrb"}],"comments":[{"id":57,"issue_id":"bd-1vv","author":"HoangNB","text":"Goal:\nExtract useful tool and file-change telemetry from Amp artifacts while truncating large before/after blobs safely.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-1w0","title":"Implement known-path discovery registry for all 5 supported agents","description":"Discover source roots across Codex, Claude, Gemini, Amp, and OpenCode with explicit path rules.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:38.649904Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.986284Z","compaction_level":0,"original_size":0,"labels":["discovery","logit","paths"],"dependencies":[{"issue_id":"bd-1w0","depends_on_id":"bd-182","type":"blocks","created_at":"2026-02-25T07:00:26.986269Z","created_by":"themrb"},{"issue_id":"bd-1w0","depends_on_id":"bd-1re","type":"parent-child","created_at":"2026-02-25T06:57:38.652269Z","created_by":"themrb"}],"comments":[{"id":26,"issue_id":"bd-1w0","author":"HoangNB","text":"Goal:\nDiscover source roots across Codex, Claude, Gemini, Amp, and OpenCode with explicit path rules.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:38Z"}]}
{"id":"bd-1x3","title":"Define command help-text examples and output expectations","description":"Provide representative command examples and expected behavior summaries for each command.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:33.888364Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.955634Z","compaction_level":0,"original_size":0,"labels":["cli","logit","subtask"],"dependencies":[{"issue_id":"bd-1x3","depends_on_id":"bd-3bu","type":"blocks","created_at":"2026-02-25T07:00:26.955619Z","created_by":"themrb"},{"issue_id":"bd-1x3","depends_on_id":"bd-3i0","type":"parent-child","created_at":"2026-02-25T06:59:33.889888Z","created_by":"themrb"}],"comments":[{"id":86,"issue_id":"bd-1x3","author":"HoangNB","text":"Subtask intent:\nProvide representative command examples and expected behavior summaries for each command.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:33Z"}]}
{"id":"bd-1xb","title":"Propagate Gemini session metadata into normalized session context","description":"Attach session-level metadata to each normalized Gemini event where available.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:34.549808Z","created_by":"themrb","updated_at":"2026-02-25T07:00:29.005370Z","compaction_level":0,"original_size":0,"labels":["gemini","logit","subtask"],"dependencies":[{"issue_id":"bd-1xb","depends_on_id":"bd-16z","type":"blocks","created_at":"2026-02-25T07:00:29.005355Z","created_by":"themrb"},{"issue_id":"bd-1xb","depends_on_id":"bd-1k0","type":"parent-child","created_at":"2026-02-25T06:59:34.552181Z","created_by":"themrb"}],"comments":[{"id":96,"issue_id":"bd-1xb","author":"HoangNB","text":"Subtask intent:\nAttach session-level metadata to each normalized Gemini event where available.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:34Z"}]}
{"id":"bd-1xy","title":"Define SQLite mirror schema aligned to canonical normalized fields","description":"Create relational schema and table contracts that preserve all canonical normalized fields and provenance metadata.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:56.677684Z","created_by":"themrb","updated_at":"2026-02-25T07:00:30.148891Z","compaction_level":0,"original_size":0,"labels":["logit","schema","sqlite"],"dependencies":[{"issue_id":"bd-1xy","depends_on_id":"bd-1kq","type":"parent-child","created_at":"2026-02-25T06:58:56.680632Z","created_by":"themrb"},{"issue_id":"bd-1xy","depends_on_id":"bd-2uh","type":"blocks","created_at":"2026-02-25T07:00:30.148875Z","created_by":"themrb"},{"issue_id":"bd-1xy","depends_on_id":"bd-343","type":"blocks","created_at":"2026-02-25T07:00:30.113950Z","created_by":"themrb"}],"comments":[{"id":64,"issue_id":"bd-1xy","author":"HoangNB","text":"Goal:\nCreate relational schema and table contracts that preserve all canonical normalized fields and provenance metadata.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:56Z"}]}
{"id":"bd-20c","title":"Emit machine-readable validation report artifact","description":"Produce a structured validation report containing pass/fail, errors, warnings, and per-agent summary statistics.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:57.015316Z","created_by":"themrb","updated_at":"2026-02-25T07:00:30.584872Z","compaction_level":0,"original_size":0,"labels":["logit","report","validate"],"dependencies":[{"issue_id":"bd-20c","depends_on_id":"bd-13n","type":"blocks","created_at":"2026-02-25T07:00:30.550348Z","created_by":"themrb"},{"issue_id":"bd-20c","depends_on_id":"bd-26k","type":"blocks","created_at":"2026-02-25T07:00:30.584851Z","created_by":"themrb"},{"issue_id":"bd-20c","depends_on_id":"bd-u6d","type":"parent-child","created_at":"2026-02-25T06:58:57.016455Z","created_by":"themrb"}],"comments":[{"id":70,"issue_id":"bd-20c","author":"HoangNB","text":"Goal:\nProduce a structured validation report containing pass/fail, errors, warnings, and per-agent summary statistics.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:57Z"}]}
{"id":"bd-21o","title":"Define and enforce validation exit code contract","description":"Guarantee stable exit codes for success, validation failure, and runtime failure to support automation.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:57.069719Z","created_by":"themrb","updated_at":"2026-02-25T07:00:30.654397Z","compaction_level":0,"original_size":0,"labels":["cli","logit","validate"],"dependencies":[{"issue_id":"bd-21o","depends_on_id":"bd-13b","type":"blocks","created_at":"2026-02-25T07:00:30.654379Z","created_by":"themrb"},{"issue_id":"bd-21o","depends_on_id":"bd-20c","type":"blocks","created_at":"2026-02-25T07:00:30.618940Z","created_by":"themrb"},{"issue_id":"bd-21o","depends_on_id":"bd-u6d","type":"parent-child","created_at":"2026-02-25T06:58:57.071180Z","created_by":"themrb"}],"comments":[{"id":71,"issue_id":"bd-21o","author":"HoangNB","text":"Goal:\nGuarantee stable exit codes for success, validation failure, and runtime failure to support automation.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:57Z"}]}
{"id":"bd-241","title":"Implement integration tests for snapshot, normalize, and validate workflows","description":"Validate end-to-end command interactions and artifact generation across the primary workflow commands.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:57.312964Z","created_by":"themrb","updated_at":"2026-02-25T07:00:31.334689Z","compaction_level":0,"original_size":0,"labels":["integration","logit","test"],"dependencies":[{"issue_id":"bd-241","depends_on_id":"bd-13y","type":"parent-child","created_at":"2026-02-25T06:58:57.314330Z","created_by":"themrb"},{"issue_id":"bd-241","depends_on_id":"bd-149","type":"blocks","created_at":"2026-02-25T07:00:31.301880Z","created_by":"themrb"},{"issue_id":"bd-241","depends_on_id":"bd-21o","type":"blocks","created_at":"2026-02-25T07:00:31.334673Z","created_by":"themrb"},{"issue_id":"bd-241","depends_on_id":"bd-29y","type":"blocks","created_at":"2026-02-25T07:00:31.228489Z","created_by":"themrb"},{"issue_id":"bd-241","depends_on_id":"bd-9eb","type":"blocks","created_at":"2026-02-25T07:00:31.264742Z","created_by":"themrb"}],"comments":[{"id":75,"issue_id":"bd-241","author":"HoangNB","text":"Goal:\nValidate end-to-end command interactions and artifact generation across the primary workflow commands.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:57Z"}]}
{"id":"bd-244","title":"Define controlled vocab for event_type, role, and record_format","description":"Freeze allowed value sets and fallback behavior for unknown source values.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:33.762524Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.691784Z","compaction_level":0,"original_size":0,"labels":["logit","schema","subtask"],"dependencies":[{"issue_id":"bd-244","depends_on_id":"bd-2hp","type":"blocks","created_at":"2026-02-25T07:00:26.691767Z","created_by":"themrb"},{"issue_id":"bd-244","depends_on_id":"bd-nn2","type":"parent-child","created_at":"2026-02-25T06:59:33.764008Z","created_by":"themrb"}],"comments":[{"id":84,"issue_id":"bd-244","author":"HoangNB","text":"Subtask intent:\nFreeze allowed value sets and fallback behavior for unknown source values.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:33Z"}]}
{"id":"bd-24b","title":"Parse OpenCode session part records (content-bearing and step events)","description":"Ingest OpenCode part records, including text and non-text step events, with preserved provenance.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:31.009853Z","created_by":"themrb","updated_at":"2026-02-25T07:00:29.535048Z","compaction_level":0,"original_size":0,"labels":["adapter","logit","opencode","parts"],"dependencies":[{"issue_id":"bd-24b","depends_on_id":"bd-28v","type":"blocks","created_at":"2026-02-25T07:00:29.535031Z","created_by":"themrb"},{"issue_id":"bd-24b","depends_on_id":"bd-xdl","type":"parent-child","created_at":"2026-02-25T06:58:31.011248Z","created_by":"themrb"}],"comments":[{"id":60,"issue_id":"bd-24b","author":"HoangNB","text":"Goal:\nIngest OpenCode part records, including text and non-text step events, with preserved provenance.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:31Z"}]}
{"id":"bd-25d","title":"Parse Amp auxiliary history/session files","description":"Capture Amp history and session metadata as auxiliary context without duplicating thread message content.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:30.786107Z","created_by":"themrb","updated_at":"2026-02-25T07:00:29.170668Z","compaction_level":0,"original_size":0,"labels":["adapter","amp","aux","logit"],"dependencies":[{"issue_id":"bd-25d","depends_on_id":"bd-2pj","type":"blocks","created_at":"2026-02-25T07:00:29.170652Z","created_by":"themrb"},{"issue_id":"bd-25d","depends_on_id":"bd-3hw","type":"parent-child","created_at":"2026-02-25T06:58:30.788140Z","created_by":"themrb"}],"comments":[{"id":56,"issue_id":"bd-25d","author":"HoangNB","text":"Goal:\nCapture Amp history and session metadata as auxiliary context without duplicating thread message content.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-26g","title":"Implement filesystem permission and unreadable-path handling policy","description":"Ensure discovery handles missing/unreadable directories without aborting global execution.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:34.011501Z","created_by":"themrb","updated_at":"2026-02-25T07:00:27.218669Z","compaction_level":0,"original_size":0,"labels":["discovery","logit","subtask"],"dependencies":[{"issue_id":"bd-26g","depends_on_id":"bd-1w0","type":"parent-child","created_at":"2026-02-25T06:59:34.012871Z","created_by":"themrb"},{"issue_id":"bd-26g","depends_on_id":"bd-8vn","type":"blocks","created_at":"2026-02-25T07:00:27.218650Z","created_by":"themrb"}],"comments":[{"id":88,"issue_id":"bd-26g","author":"HoangNB","text":"Subtask intent:\nEnsure discovery handles missing/unreadable directories without aborting global execution.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:34Z"}]}
{"id":"bd-26k","title":"Implement invariant checks and strict-mode policy","description":"Add semantic checks beyond schema (required keys, timestamp sanity, null-rate heuristics) with optional strict mode.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:56.965916Z","created_by":"themrb","updated_at":"2026-02-25T07:00:30.517185Z","compaction_level":0,"original_size":0,"labels":["invariants","logit","validate"],"dependencies":[{"issue_id":"bd-26k","depends_on_id":"bd-13n","type":"blocks","created_at":"2026-02-25T07:00:30.483654Z","created_by":"themrb"},{"issue_id":"bd-26k","depends_on_id":"bd-nn2","type":"blocks","created_at":"2026-02-25T07:00:30.517167Z","created_by":"themrb"},{"issue_id":"bd-26k","depends_on_id":"bd-u6d","type":"parent-child","created_at":"2026-02-25T06:58:56.967061Z","created_by":"themrb"}],"comments":[{"id":69,"issue_id":"bd-26k","author":"HoangNB","text":"Goal:\nAdd semantic checks beyond schema (required keys, timestamp sanity, null-rate heuristics) with optional strict mode.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:56Z"}]}
{"id":"bd-280","title":"Epic: Architecture, Contracts, and Safety Defaults","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-25T06:56:29.137994Z","created_by":"themrb","updated_at":"2026-02-25T06:56:29.618237Z","compaction_level":0,"original_size":0,"labels":["architecture","epic","logit"],"dependencies":[{"issue_id":"bd-280","depends_on_id":"bd-1d7","type":"parent-child","created_at":"2026-02-25T06:56:29.139517Z","created_by":"themrb"}],"comments":[{"id":2,"issue_id":"bd-280","author":"HoangNB","text":"Intent:\nDefine irreversible project decisions early so downstream implementation is deterministic and low-friction.\n\nScope:\n- Canonical schema contract (agentlog.v1)\n- Output artifact topology and naming\n- Safety defaults (what is retained vs redacted in which mode)\n- Non-goals and compatibility boundaries\n\nWhy this matters:\nWithout stable contracts, adapter and pipeline work diverges and causes expensive rework.\n","created_at":"2026-02-25T06:56:29Z"}]}
{"id":"bd-28v","title":"Parse OpenCode session info and message metadata records","description":"Ingest OpenCode session info and message metadata rows as the base layer for later content joins.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:30.954486Z","created_by":"themrb","updated_at":"2026-02-25T07:00:29.497595Z","compaction_level":0,"original_size":0,"labels":["adapter","logit","message-meta","opencode"],"dependencies":[{"issue_id":"bd-28v","depends_on_id":"bd-2x6","type":"blocks","created_at":"2026-02-25T07:00:29.497580Z","created_by":"themrb"},{"issue_id":"bd-28v","depends_on_id":"bd-343","type":"blocks","created_at":"2026-02-25T07:00:29.460863Z","created_by":"themrb"},{"issue_id":"bd-28v","depends_on_id":"bd-xdl","type":"parent-child","created_at":"2026-02-25T06:58:30.956223Z","created_by":"themrb"}],"comments":[{"id":59,"issue_id":"bd-28v","author":"HoangNB","text":"Goal:\nIngest OpenCode session info and message metadata rows as the base layer for later content joins.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-29m","title":"Implement sensitive-pattern matcher catalog for snapshot redaction","description":"Define regex and heuristic catalog for secrets/tokens and apply deterministic masking.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:34.085391Z","created_by":"themrb","updated_at":"2026-02-25T06:59:34.146697Z","compaction_level":0,"original_size":0,"labels":["logit","snapshot","subtask"],"dependencies":[{"issue_id":"bd-29m","depends_on_id":"bd-3ew","type":"parent-child","created_at":"2026-02-25T06:59:34.087038Z","created_by":"themrb"}],"comments":[{"id":89,"issue_id":"bd-29m","author":"HoangNB","text":"Subtask intent:\nDefine regex and heuristic catalog for secrets/tokens and apply deterministic masking.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:34Z"}]}
{"id":"bd-29y","title":"Build fixture corpus layout for all supported agent source shapes","description":"Establish a reusable fixture corpus that captures representative and edge-case source payloads for every adapter.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:57.130242Z","created_by":"themrb","updated_at":"2026-02-25T07:00:30.896395Z","compaction_level":0,"original_size":0,"labels":["fixtures","logit","test"],"dependencies":[{"issue_id":"bd-29y","depends_on_id":"bd-13y","type":"parent-child","created_at":"2026-02-25T06:58:57.131668Z","created_by":"themrb"},{"issue_id":"bd-29y","depends_on_id":"bd-1a1","type":"blocks","created_at":"2026-02-25T07:00:30.865392Z","created_by":"themrb"},{"issue_id":"bd-29y","depends_on_id":"bd-2yx","type":"blocks","created_at":"2026-02-25T07:00:30.896378Z","created_by":"themrb"},{"issue_id":"bd-29y","depends_on_id":"bd-3uo","type":"blocks","created_at":"2026-02-25T07:00:30.791560Z","created_by":"themrb"},{"issue_id":"bd-29y","depends_on_id":"bd-4t2","type":"blocks","created_at":"2026-02-25T07:00:30.829848Z","created_by":"themrb"},{"issue_id":"bd-29y","depends_on_id":"bd-fqr","type":"blocks","created_at":"2026-02-25T07:00:30.759265Z","created_by":"themrb"}],"comments":[{"id":72,"issue_id":"bd-29y","author":"HoangNB","text":"Goal:\nEstablish a reusable fixture corpus that captures representative and edge-case source payloads for every adapter.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:57Z"}]}
{"id":"bd-29z","title":"Implement SQLite indexes and query sanity checks","description":"Add practical indexes and basic query sanity checks to ensure local analytics performance and correctness.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:56.791356Z","created_by":"themrb","updated_at":"2026-02-25T07:00:30.250051Z","compaction_level":0,"original_size":0,"labels":["indexing","logit","sqlite"],"dependencies":[{"issue_id":"bd-29z","depends_on_id":"bd-10h","type":"blocks","created_at":"2026-02-25T07:00:30.250033Z","created_by":"themrb"},{"issue_id":"bd-29z","depends_on_id":"bd-1kq","type":"parent-child","created_at":"2026-02-25T06:58:56.792753Z","created_by":"themrb"}],"comments":[{"id":66,"issue_id":"bd-29z","author":"HoangNB","text":"Goal:\nAdd practical indexes and basic query sanity checks to ensure local analytics performance and correctness.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:56Z"}]}
{"id":"bd-2hp","title":"Create required-versus-optional field matrix for agentlog.v1","description":"Document explicit required/optional status and null semantics for each canonical field.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:33.674520Z","created_by":"themrb","updated_at":"2026-02-25T06:59:33.722060Z","compaction_level":0,"original_size":0,"labels":["logit","schema","subtask"],"dependencies":[{"issue_id":"bd-2hp","depends_on_id":"bd-nn2","type":"parent-child","created_at":"2026-02-25T06:59:33.677774Z","created_by":"themrb"}],"comments":[{"id":83,"issue_id":"bd-2hp","author":"HoangNB","text":"Subtask intent:\nDocument explicit required/optional status and null semantics for each canonical field.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:33Z"}]}
{"id":"bd-2il","title":"Implement adapter-level mapping tests for all five adapters","description":"Verify each adapter mapping contract and edge-case handling against fixture inputs and expected canonical outputs.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:57.249173Z","created_by":"themrb","updated_at":"2026-02-25T07:00:31.195861Z","compaction_level":0,"original_size":0,"labels":["adapters","logit","test"],"dependencies":[{"issue_id":"bd-2il","depends_on_id":"bd-13y","type":"parent-child","created_at":"2026-02-25T06:58:57.250715Z","created_by":"themrb"},{"issue_id":"bd-2il","depends_on_id":"bd-1a1","type":"blocks","created_at":"2026-02-25T07:00:31.164051Z","created_by":"themrb"},{"issue_id":"bd-2il","depends_on_id":"bd-29y","type":"blocks","created_at":"2026-02-25T07:00:31.027595Z","created_by":"themrb"},{"issue_id":"bd-2il","depends_on_id":"bd-2yx","type":"blocks","created_at":"2026-02-25T07:00:31.195838Z","created_by":"themrb"},{"issue_id":"bd-2il","depends_on_id":"bd-3uo","type":"blocks","created_at":"2026-02-25T07:00:31.096862Z","created_by":"themrb"},{"issue_id":"bd-2il","depends_on_id":"bd-4t2","type":"blocks","created_at":"2026-02-25T07:00:31.131960Z","created_by":"themrb"},{"issue_id":"bd-2il","depends_on_id":"bd-fqr","type":"blocks","created_at":"2026-02-25T07:00:31.061548Z","created_by":"themrb"}],"comments":[{"id":74,"issue_id":"bd-2il","author":"HoangNB","text":"Goal:\nVerify each adapter mapping contract and edge-case handling against fixture inputs and expected canonical outputs.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:57Z"}]}
{"id":"bd-2j8","title":"Parse Codex rollout JSONL primary event stream","description":"Map Codex rollout JSONL records (including response_item and event_msg families) into canonical events with provenance.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:29.974193Z","created_by":"themrb","updated_at":"2026-02-25T07:00:28.209636Z","compaction_level":0,"original_size":0,"labels":["adapter","codex","logit","rollout"],"dependencies":[{"issue_id":"bd-2j8","depends_on_id":"bd-1ly","type":"blocks","created_at":"2026-02-25T07:00:28.209621Z","created_by":"themrb"},{"issue_id":"bd-2j8","depends_on_id":"bd-343","type":"blocks","created_at":"2026-02-25T07:00:28.177812Z","created_by":"themrb"},{"issue_id":"bd-2j8","depends_on_id":"bd-398","type":"parent-child","created_at":"2026-02-25T06:58:29.976829Z","created_by":"themrb"}],"comments":[{"id":42,"issue_id":"bd-2j8","author":"HoangNB","text":"Goal:\nMap Codex rollout JSONL records (including response_item and event_msg families) into canonical events with provenance.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-2lr","title":"Implement source classification (jsonl/json/text-log/binary)","description":"Classify discovered artifacts so downstream processors choose correct parsers and safety handling.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:38.714161Z","created_by":"themrb","updated_at":"2026-02-25T07:00:27.020327Z","compaction_level":0,"original_size":0,"labels":["classifier","discovery","logit"],"dependencies":[{"issue_id":"bd-2lr","depends_on_id":"bd-1re","type":"parent-child","created_at":"2026-02-25T06:57:38.715443Z","created_by":"themrb"},{"issue_id":"bd-2lr","depends_on_id":"bd-1w0","type":"blocks","created_at":"2026-02-25T07:00:27.020312Z","created_by":"themrb"}],"comments":[{"id":27,"issue_id":"bd-2lr","author":"HoangNB","text":"Goal:\nClassify discovered artifacts so downstream processors choose correct parsers and safety handling.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:38Z"}]}
{"id":"bd-2n2","title":"Specify run artifact topology and manifest contract under ~/.logit/output","description":"Freeze directory layout, naming, and per-run metadata files so outputs are predictable and automation-friendly.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:38.119063Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.505761Z","compaction_level":0,"original_size":0,"labels":["architecture","artifacts","logit"],"dependencies":[{"issue_id":"bd-2n2","depends_on_id":"bd-280","type":"parent-child","created_at":"2026-02-25T06:57:38.120388Z","created_by":"themrb"},{"issue_id":"bd-2n2","depends_on_id":"bd-nn2","type":"blocks","created_at":"2026-02-25T07:00:26.505745Z","created_by":"themrb"}],"comments":[{"id":17,"issue_id":"bd-2n2","author":"HoangNB","text":"Goal:\nFreeze directory layout, naming, and per-run metadata files so outputs are predictable and automation-friendly.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:38Z"}]}
{"id":"bd-2o7","title":"Build per-adapter expectation tables from fixture corpus","description":"Define expected canonical outputs per fixture so adapter regressions are precisely detectable.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:35.333775Z","created_by":"themrb","updated_at":"2026-02-25T06:59:35.370340Z","compaction_level":0,"original_size":0,"labels":["logit","subtask","test"],"dependencies":[{"issue_id":"bd-2o7","depends_on_id":"bd-2il","type":"parent-child","created_at":"2026-02-25T06:59:35.335252Z","created_by":"themrb"}],"comments":[{"id":109,"issue_id":"bd-2o7","author":"HoangNB","text":"Subtask intent:\nDefine expected canonical outputs per fixture so adapter regressions are precisely detectable.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:35Z"}]}
{"id":"bd-2pj","title":"Parse Amp thread JSON envelopes and thread-level metadata","description":"Ingest Amp thread containers and extract stable thread/session metadata required for canonical event context.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:30.671224Z","created_by":"themrb","updated_at":"2026-02-25T07:00:29.074314Z","compaction_level":0,"original_size":0,"labels":["adapter","amp","logit","threads"],"dependencies":[{"issue_id":"bd-2pj","depends_on_id":"bd-2x6","type":"blocks","created_at":"2026-02-25T07:00:29.074294Z","created_by":"themrb"},{"issue_id":"bd-2pj","depends_on_id":"bd-343","type":"blocks","created_at":"2026-02-25T07:00:29.041695Z","created_by":"themrb"},{"issue_id":"bd-2pj","depends_on_id":"bd-3hw","type":"parent-child","created_at":"2026-02-25T06:58:30.672684Z","created_by":"themrb"}],"comments":[{"id":54,"issue_id":"bd-2pj","author":"HoangNB","text":"Goal:\nIngest Amp thread containers and extract stable thread/session metadata required for canonical event context.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-2tt","title":"Write privacy, safety, and known-limitations documentation","description":"Document data handling defaults, redaction behavior, and intentional v1 limitations for operator clarity.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:57.614843Z","created_by":"themrb","updated_at":"2026-02-25T07:00:32.003768Z","compaction_level":0,"original_size":0,"labels":["docs","logit","safety"],"dependencies":[{"issue_id":"bd-2tt","depends_on_id":"bd-1gt","type":"blocks","created_at":"2026-02-25T07:00:31.933365Z","created_by":"themrb"},{"issue_id":"bd-2tt","depends_on_id":"bd-26k","type":"blocks","created_at":"2026-02-25T07:00:32.003748Z","created_by":"themrb"},{"issue_id":"bd-2tt","depends_on_id":"bd-3ew","type":"blocks","created_at":"2026-02-25T07:00:31.969528Z","created_by":"themrb"},{"issue_id":"bd-2tt","depends_on_id":"bd-5k4","type":"parent-child","created_at":"2026-02-25T06:58:57.616188Z","created_by":"themrb"}],"comments":[{"id":80,"issue_id":"bd-2tt","author":"HoangNB","text":"Goal:\nDocument data handling defaults, redaction behavior, and intentional v1 limitations for operator clarity.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:57Z"}]}
{"id":"bd-2uh","title":"Implement normalized JSONL writer, schema writer, and stats writer","description":"Emit canonical artifacts (events.jsonl, schema, stats) required for downstream consumption and QA.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:39.491941Z","created_by":"themrb","updated_at":"2026-02-25T07:00:27.846202Z","compaction_level":0,"original_size":0,"labels":["artifacts","logit","normalize"],"dependencies":[{"issue_id":"bd-2uh","depends_on_id":"bd-165","type":"parent-child","created_at":"2026-02-25T06:57:39.493093Z","created_by":"themrb"},{"issue_id":"bd-2uh","depends_on_id":"bd-343","type":"blocks","created_at":"2026-02-25T07:00:27.816208Z","created_by":"themrb"},{"issue_id":"bd-2uh","depends_on_id":"bd-9ej","type":"blocks","created_at":"2026-02-25T07:00:27.846187Z","created_by":"themrb"}],"comments":[{"id":40,"issue_id":"bd-2uh","author":"HoangNB","text":"Goal:\nEmit canonical artifacts (, schema, stats) required for downstream consumption and QA.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:39Z"}]}
{"id":"bd-2vc","title":"Parse Claude project session JSONL event records","description":"Map primary Claude project session records (user, assistant, progress, system) into canonical events with preserved roles.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:30.214737Z","created_by":"themrb","updated_at":"2026-02-25T07:00:28.494577Z","compaction_level":0,"original_size":0,"labels":["adapter","claude","logit","session"],"dependencies":[{"issue_id":"bd-2vc","depends_on_id":"bd-1ly","type":"blocks","created_at":"2026-02-25T07:00:28.494562Z","created_by":"themrb"},{"issue_id":"bd-2vc","depends_on_id":"bd-343","type":"blocks","created_at":"2026-02-25T07:00:28.463919Z","created_by":"themrb"},{"issue_id":"bd-2vc","depends_on_id":"bd-lb0","type":"parent-child","created_at":"2026-02-25T06:58:30.216415Z","created_by":"themrb"}],"comments":[{"id":46,"issue_id":"bd-2vc","author":"HoangNB","text":"Goal:\nMap primary Claude project session records (user, assistant, progress, system) into canonical events with preserved roles.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-2x6","title":"Implement timestamp normalization utilities and canonical UTC conversion","description":"Normalize heterogeneous time formats into a single comparable representation with robust fallbacks.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:39.321924Z","created_by":"themrb","updated_at":"2026-02-25T07:00:27.624095Z","compaction_level":0,"original_size":0,"labels":["logit","normalize","time"],"dependencies":[{"issue_id":"bd-2x6","depends_on_id":"bd-165","type":"parent-child","created_at":"2026-02-25T06:57:39.323506Z","created_by":"themrb"},{"issue_id":"bd-2x6","depends_on_id":"bd-1mo","type":"blocks","created_at":"2026-02-25T07:00:27.624078Z","created_by":"themrb"}],"comments":[{"id":37,"issue_id":"bd-2x6","author":"HoangNB","text":"Goal:\nNormalize heterogeneous time formats into a single comparable representation with robust fallbacks.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:39Z"}]}
{"id":"bd-2yx","title":"OpenCode adapter edge-case handling and mapping verification","description":"Consolidate OpenCode join, nullability, and part-type variance into explicit mapping verification cases.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:31.185083Z","created_by":"themrb","updated_at":"2026-02-25T07:00:29.754762Z","compaction_level":0,"original_size":0,"labels":["adapter","logit","opencode","quality"],"dependencies":[{"issue_id":"bd-2yx","depends_on_id":"bd-24b","type":"blocks","created_at":"2026-02-25T07:00:29.694657Z","created_by":"themrb"},{"issue_id":"bd-2yx","depends_on_id":"bd-28v","type":"blocks","created_at":"2026-02-25T07:00:29.663991Z","created_by":"themrb"},{"issue_id":"bd-2yx","depends_on_id":"bd-32e","type":"blocks","created_at":"2026-02-25T07:00:29.724858Z","created_by":"themrb"},{"issue_id":"bd-2yx","depends_on_id":"bd-xdl","type":"parent-child","created_at":"2026-02-25T06:58:31.187064Z","created_by":"themrb"},{"issue_id":"bd-2yx","depends_on_id":"bd-yr2","type":"blocks","created_at":"2026-02-25T07:00:29.754746Z","created_by":"themrb"}],"comments":[{"id":63,"issue_id":"bd-2yx","author":"HoangNB","text":"Goal:\nConsolidate OpenCode join, nullability, and part-type variance into explicit mapping verification cases.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:31Z"}]}
{"id":"bd-32e","title":"Implement OpenCode message-to-part join strategy with graceful failure behavior","description":"Join OpenCode part records to message metadata via IDs and define explicit behavior for missing join targets.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:31.069171Z","created_by":"themrb","updated_at":"2026-02-25T07:00:29.599338Z","compaction_level":0,"original_size":0,"labels":["adapter","join","logit","opencode"],"dependencies":[{"issue_id":"bd-32e","depends_on_id":"bd-24b","type":"blocks","created_at":"2026-02-25T07:00:29.599320Z","created_by":"themrb"},{"issue_id":"bd-32e","depends_on_id":"bd-28v","type":"blocks","created_at":"2026-02-25T07:00:29.566985Z","created_by":"themrb"},{"issue_id":"bd-32e","depends_on_id":"bd-xdl","type":"parent-child","created_at":"2026-02-25T06:58:31.070886Z","created_by":"themrb"}],"comments":[{"id":61,"issue_id":"bd-32e","author":"HoangNB","text":"Goal:\nJoin OpenCode part records to message metadata via IDs and define explicit behavior for missing join targets.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:31Z"}]}
{"id":"bd-32g","title":"Implement inspect command baseline for source and normalized files","description":"Provide read-only introspection to quickly inspect inputs and outputs without custom scripts.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:57:38.583645Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.882875Z","compaction_level":0,"original_size":0,"labels":["cli","inspect","logit"],"dependencies":[{"issue_id":"bd-32g","depends_on_id":"bd-182","type":"blocks","created_at":"2026-02-25T07:00:26.882857Z","created_by":"themrb"},{"issue_id":"bd-32g","depends_on_id":"bd-3i0","type":"blocks","created_at":"2026-02-25T07:00:26.850417Z","created_by":"themrb"},{"issue_id":"bd-32g","depends_on_id":"bd-soe","type":"parent-child","created_at":"2026-02-25T06:57:38.585214Z","created_by":"themrb"}],"comments":[{"id":25,"issue_id":"bd-32g","author":"HoangNB","text":"Goal:\nProvide read-only introspection to quickly inspect inputs and outputs without custom scripts.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:38Z"}]}
{"id":"bd-343","title":"Implement canonical Rust structs and schema generation for agentlog.v1","description":"Define the in-code data model and emit machine-readable schema artifact for validation and consumers.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:39.252525Z","created_by":"themrb","updated_at":"2026-02-25T07:00:27.590837Z","compaction_level":0,"original_size":0,"labels":["logit","normalize","schema"],"dependencies":[{"issue_id":"bd-343","depends_on_id":"bd-165","type":"parent-child","created_at":"2026-02-25T06:57:39.253992Z","created_by":"themrb"},{"issue_id":"bd-343","depends_on_id":"bd-2n2","type":"blocks","created_at":"2026-02-25T07:00:27.590820Z","created_by":"themrb"},{"issue_id":"bd-343","depends_on_id":"bd-nn2","type":"blocks","created_at":"2026-02-25T07:00:27.556562Z","created_by":"themrb"}],"comments":[{"id":36,"issue_id":"bd-343","author":"HoangNB","text":"Goal:\nDefine the in-code data model and emit machine-readable schema artifact for validation and consumers.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:39Z"}]}
{"id":"bd-34x","title":"Extract Amp typed message content parts into canonical text and parts","description":"Normalize Amp nested typed content arrays into full text, excerpts, and structured content_parts.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:30.723235Z","created_by":"themrb","updated_at":"2026-02-25T07:00:29.136932Z","compaction_level":0,"original_size":0,"labels":["adapter","amp","content","logit"],"dependencies":[{"issue_id":"bd-34x","depends_on_id":"bd-1ly","type":"blocks","created_at":"2026-02-25T07:00:29.136916Z","created_by":"themrb"},{"issue_id":"bd-34x","depends_on_id":"bd-2pj","type":"blocks","created_at":"2026-02-25T07:00:29.106139Z","created_by":"themrb"},{"issue_id":"bd-34x","depends_on_id":"bd-3hw","type":"parent-child","created_at":"2026-02-25T06:58:30.725059Z","created_by":"themrb"}],"comments":[{"id":55,"issue_id":"bd-34x","author":"HoangNB","text":"Goal:\nNormalize Amp nested typed content arrays into full text, excerpts, and structured content_parts.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-35t","title":"Map Codex event_msg metadata into typed meta/progress records","description":"Translate non-message operational events into consistent meta/progress event categories.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:34.308918Z","created_by":"themrb","updated_at":"2026-02-25T07:00:28.433266Z","compaction_level":0,"original_size":0,"labels":["codex","logit","subtask"],"dependencies":[{"issue_id":"bd-35t","depends_on_id":"bd-2j8","type":"parent-child","created_at":"2026-02-25T06:59:34.310419Z","created_by":"themrb"},{"issue_id":"bd-35t","depends_on_id":"bd-9bi","type":"blocks","created_at":"2026-02-25T07:00:28.433251Z","created_by":"themrb"}],"comments":[{"id":92,"issue_id":"bd-35t","author":"HoangNB","text":"Subtask intent:\nTranslate non-message operational events into consistent meta/progress event categories.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:34Z"}]}
{"id":"bd-386","title":"Scaffold Rust crate and module boundaries for logit","description":"Create the foundational crate structure and module map to support adapter fan-in and command growth cleanly.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:38.354964Z","created_by":"themrb","updated_at":"2026-02-25T06:58:29.727589Z","compaction_level":0,"original_size":0,"labels":["cli","logit","rust"],"dependencies":[{"issue_id":"bd-386","depends_on_id":"bd-soe","type":"parent-child","created_at":"2026-02-25T06:57:38.356220Z","created_by":"themrb"}],"comments":[{"id":21,"issue_id":"bd-386","author":"HoangNB","text":"Goal:\nCreate the foundational crate structure and module map to support adapter fan-in and command growth cleanly.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:38Z"}]}
{"id":"bd-38g","title":"Epic: Gemini Adapter","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-25T06:56:29.345572Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.063110Z","compaction_level":0,"original_size":0,"labels":["adapter","epic","gemini","logit"],"dependencies":[{"issue_id":"bd-38g","depends_on_id":"bd-1d7","type":"parent-child","created_at":"2026-02-25T06:56:29.346960Z","created_by":"themrb"},{"issue_id":"bd-38g","depends_on_id":"bd-280","type":"blocks","created_at":"2026-02-25T07:00:26.063090Z","created_by":"themrb"}],"comments":[{"id":8,"issue_id":"bd-38g","author":"HoangNB","text":"Intent:\nNormalize Gemini JSON sources and explicitly treat protobuf artifacts as indexed-only in v1.\n\nConsiderations:\n- logs.json may be sparse/empty\n- chats session files carry core message payloads\n- protobuf decoding intentionally deferred to avoid premature complexity\n","created_at":"2026-02-25T06:56:29Z"}]}
{"id":"bd-38v","title":"Add validate workflow exit-code and report-shape tests","description":"Verify validate command returns correct exit codes and report structures across pass/fail cases.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:35.533872Z","created_by":"themrb","updated_at":"2026-02-25T07:00:31.699141Z","compaction_level":0,"original_size":0,"labels":["logit","subtask","test"],"dependencies":[{"issue_id":"bd-38v","depends_on_id":"bd-21o","type":"blocks","created_at":"2026-02-25T07:00:31.699124Z","created_by":"themrb"},{"issue_id":"bd-38v","depends_on_id":"bd-241","type":"parent-child","created_at":"2026-02-25T06:59:35.535777Z","created_by":"themrb"},{"issue_id":"bd-38v","depends_on_id":"bd-if6","type":"blocks","created_at":"2026-02-25T07:00:31.662819Z","created_by":"themrb"}],"comments":[{"id":112,"issue_id":"bd-38v","author":"HoangNB","text":"Subtask intent:\nVerify validate command returns correct exit codes and report structures across pass/fail cases.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:35Z"}]}
{"id":"bd-398","title":"Epic: Codex Adapter","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-25T06:56:29.277451Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.014822Z","compaction_level":0,"original_size":0,"labels":["adapter","codex","epic","logit"],"dependencies":[{"issue_id":"bd-398","depends_on_id":"bd-1d7","type":"parent-child","created_at":"2026-02-25T06:56:29.278898Z","created_by":"themrb"},{"issue_id":"bd-398","depends_on_id":"bd-280","type":"blocks","created_at":"2026-02-25T07:00:26.014807Z","created_by":"themrb"}],"comments":[{"id":6,"issue_id":"bd-398","author":"HoangNB","text":"Intent:\nNormalize Codex local artifacts into canonical events while preserving provenance.\n\nConsiderations:\n- rollout JSONL event types differ (response_item, event_msg, etc.)\n- history and tui logs provide auxiliary context\n- avoid duplicate inflation between history and rollout streams\n","created_at":"2026-02-25T06:56:29Z"}]}
{"id":"bd-39f","title":"Implement zsh history parser and per-agent command frequency scoring","description":"Use shell command frequency as a prioritization signal while keeping filesystem discovery authoritative.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:57:38.771416Z","created_by":"themrb","updated_at":"2026-02-25T07:00:27.052243Z","compaction_level":0,"original_size":0,"labels":["discovery","history","logit"],"dependencies":[{"issue_id":"bd-39f","depends_on_id":"bd-182","type":"blocks","created_at":"2026-02-25T07:00:27.052227Z","created_by":"themrb"},{"issue_id":"bd-39f","depends_on_id":"bd-1re","type":"parent-child","created_at":"2026-02-25T06:57:38.772928Z","created_by":"themrb"}],"comments":[{"id":28,"issue_id":"bd-39f","author":"HoangNB","text":"Goal:\nUse shell command frequency as a prioritization signal while keeping filesystem discovery authoritative.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:38Z"}]}
{"id":"bd-39z","title":"Epic: Snapshot Pipeline (schema profile + representative samples)","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-25T06:56:29.245712Z","created_by":"themrb","updated_at":"2026-02-25T07:00:25.989880Z","compaction_level":0,"original_size":0,"labels":["epic","logit","snapshot"],"dependencies":[{"issue_id":"bd-39z","depends_on_id":"bd-1d7","type":"parent-child","created_at":"2026-02-25T06:56:29.247086Z","created_by":"themrb"},{"issue_id":"bd-39z","depends_on_id":"bd-1re","type":"blocks","created_at":"2026-02-25T07:00:25.962799Z","created_by":"themrb"},{"issue_id":"bd-39z","depends_on_id":"bd-280","type":"blocks","created_at":"2026-02-25T07:00:25.989857Z","created_by":"themrb"}],"comments":[{"id":5,"issue_id":"bd-39z","author":"HoangNB","text":"Intent:\nProduce safe, representative source snapshots that are useful for debugging adapters and auditing ingestion quality.\n\nScope:\n- per-source schema/key profiling\n- event type frequency summaries\n- sample capture (default 3) with redaction safeguards\n\nReasoning:\nSnapshots are observability primitives for ingestion correctness.\n","created_at":"2026-02-25T06:56:29Z"}]}
{"id":"bd-3a3","title":"Implement orphan-part strategy for missing join targets","description":"Define explicit behavior and tagging for parts that cannot be joined to message metadata.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:34.807020Z","created_by":"themrb","updated_at":"2026-02-25T07:00:29.810985Z","compaction_level":0,"original_size":0,"labels":["logit","opencode","subtask"],"dependencies":[{"issue_id":"bd-3a3","depends_on_id":"bd-1c4","type":"blocks","created_at":"2026-02-25T07:00:29.810969Z","created_by":"themrb"},{"issue_id":"bd-3a3","depends_on_id":"bd-32e","type":"parent-child","created_at":"2026-02-25T06:59:34.808434Z","created_by":"themrb"}],"comments":[{"id":100,"issue_id":"bd-3a3","author":"HoangNB","text":"Subtask intent:\nDefine explicit behavior and tagging for parts that cannot be joined to message metadata.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:34Z"}]}
{"id":"bd-3bu","title":"Define command and flag parity matrix across subcommands","description":"Specify mandatory and optional flags per subcommand and shared global behavior.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:33.825058Z","created_by":"themrb","updated_at":"2026-02-25T06:59:33.859757Z","compaction_level":0,"original_size":0,"labels":["cli","logit","subtask"],"dependencies":[{"issue_id":"bd-3bu","depends_on_id":"bd-3i0","type":"parent-child","created_at":"2026-02-25T06:59:33.826781Z","created_by":"themrb"}],"comments":[{"id":85,"issue_id":"bd-3bu","author":"HoangNB","text":"Subtask intent:\nSpecify mandatory and optional flags per subcommand and shared global behavior.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:33Z"}]}
{"id":"bd-3ck","title":"Configure CI test matrix and deterministic execution settings","description":"Define CI execution strategy, deterministic settings, and quality gates for ongoing reliability.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:57.426602Z","created_by":"themrb","updated_at":"2026-02-25T07:00:31.531719Z","compaction_level":0,"original_size":0,"labels":["ci","logit","test"],"dependencies":[{"issue_id":"bd-3ck","depends_on_id":"bd-13y","type":"parent-child","created_at":"2026-02-25T06:58:57.428237Z","created_by":"themrb"},{"issue_id":"bd-3ck","depends_on_id":"bd-241","type":"blocks","created_at":"2026-02-25T07:00:31.497510Z","created_by":"themrb"},{"issue_id":"bd-3ck","depends_on_id":"bd-2il","type":"blocks","created_at":"2026-02-25T07:00:31.465553Z","created_by":"themrb"},{"issue_id":"bd-3ck","depends_on_id":"bd-3t3","type":"blocks","created_at":"2026-02-25T07:00:31.431756Z","created_by":"themrb"},{"issue_id":"bd-3ck","depends_on_id":"bd-9rt","type":"blocks","created_at":"2026-02-25T07:00:31.531701Z","created_by":"themrb"}],"comments":[{"id":77,"issue_id":"bd-3ck","author":"HoangNB","text":"Goal:\nDefine CI execution strategy, deterministic settings, and quality gates for ongoing reliability.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:57Z"}]}
{"id":"bd-3di","title":"Implement Claude content fallback chain for text extraction","description":"Define extraction precedence across message.content, message.text, and fallback serialization.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:34.430007Z","created_by":"themrb","updated_at":"2026-02-25T07:00:28.711907Z","compaction_level":0,"original_size":0,"labels":["claude","logit","subtask"],"dependencies":[{"issue_id":"bd-3di","depends_on_id":"bd-1h0","type":"blocks","created_at":"2026-02-25T07:00:28.711892Z","created_by":"themrb"},{"issue_id":"bd-3di","depends_on_id":"bd-2vc","type":"parent-child","created_at":"2026-02-25T06:59:34.431713Z","created_by":"themrb"}],"comments":[{"id":94,"issue_id":"bd-3di","author":"HoangNB","text":"Subtask intent:\nDefine extraction precedence across message.content, message.text, and fallback serialization.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:34Z"}]}
{"id":"bd-3dx","title":"Implement normalize stage boundaries and artifact write checkpoints","description":"Define stage transitions and artifact write checkpoints to improve observability and recoverability.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:35.047263Z","created_by":"themrb","updated_at":"2026-02-25T07:00:28.141775Z","compaction_level":0,"original_size":0,"labels":["logit","normalize","subtask"],"dependencies":[{"issue_id":"bd-3dx","depends_on_id":"bd-9eb","type":"parent-child","created_at":"2026-02-25T06:59:35.048952Z","created_by":"themrb"},{"issue_id":"bd-3dx","depends_on_id":"bd-asg","type":"blocks","created_at":"2026-02-25T07:00:28.141761Z","created_by":"themrb"}],"comments":[{"id":104,"issue_id":"bd-3dx","author":"HoangNB","text":"Subtask intent:\nDefine stage transitions and artifact write checkpoints to improve observability and recoverability.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:35Z"}]}
{"id":"bd-3ew","title":"Implement snapshot redaction and truncation pipeline","description":"Protect sensitive values in snapshot outputs while preserving enough context for troubleshooting.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:39.073770Z","created_by":"themrb","updated_at":"2026-02-25T07:00:27.338489Z","compaction_level":0,"original_size":0,"labels":["logit","safety","snapshot"],"dependencies":[{"issue_id":"bd-3ew","depends_on_id":"bd-1gt","type":"blocks","created_at":"2026-02-25T07:00:27.310171Z","created_by":"themrb"},{"issue_id":"bd-3ew","depends_on_id":"bd-39z","type":"parent-child","created_at":"2026-02-25T06:57:39.075035Z","created_by":"themrb"},{"issue_id":"bd-3ew","depends_on_id":"bd-3jn","type":"blocks","created_at":"2026-02-25T07:00:27.338471Z","created_by":"themrb"}],"comments":[{"id":33,"issue_id":"bd-3ew","author":"HoangNB","text":"Goal:\nProtect sensitive values in snapshot outputs while preserving enough context for troubleshooting.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:39Z"}]}
{"id":"bd-3hw","title":"Epic: Amp Adapter","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-25T06:56:29.385439Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.087500Z","compaction_level":0,"original_size":0,"labels":["adapter","amp","epic","logit"],"dependencies":[{"issue_id":"bd-3hw","depends_on_id":"bd-1d7","type":"parent-child","created_at":"2026-02-25T06:56:29.387010Z","created_by":"themrb"},{"issue_id":"bd-3hw","depends_on_id":"bd-280","type":"blocks","created_at":"2026-02-25T07:00:26.087482Z","created_by":"themrb"}],"comments":[{"id":9,"issue_id":"bd-3hw","author":"HoangNB","text":"Intent:\nNormalize Amp thread/message payloads and reconcile auxiliary file-change telemetry.\n\nConsiderations:\n- message content often nested as typed parts\n- file-change artifacts can be large and sensitive\n- keep transform deterministic and avoid over-parsing blobs\n","created_at":"2026-02-25T06:56:29Z"}]}
{"id":"bd-3i0","title":"Implement clap command surface (snapshot, normalize, inspect, validate)","description":"Expose stable user-facing commands and flags aligned with the project contract and acceptance flow.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:38.413980Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.723486Z","compaction_level":0,"original_size":0,"labels":["cli","commands","logit"],"dependencies":[{"issue_id":"bd-3i0","depends_on_id":"bd-386","type":"blocks","created_at":"2026-02-25T07:00:26.723469Z","created_by":"themrb"},{"issue_id":"bd-3i0","depends_on_id":"bd-soe","type":"parent-child","created_at":"2026-02-25T06:57:38.415433Z","created_by":"themrb"}],"comments":[{"id":22,"issue_id":"bd-3i0","author":"HoangNB","text":"Goal:\nExpose stable user-facing commands and flags aligned with the project contract and acceptance flow.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:38Z"}]}
{"id":"bd-3jm","title":"Define dedupe/provenance policy using raw hashes and fallback keys","description":"Prevent duplicate inflation while preserving traceability from normalized records back to source artifacts.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:38.291500Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.659485Z","compaction_level":0,"original_size":0,"labels":["architecture","dedupe","logit"],"dependencies":[{"issue_id":"bd-3jm","depends_on_id":"bd-1mo","type":"blocks","created_at":"2026-02-25T07:00:26.659468Z","created_by":"themrb"},{"issue_id":"bd-3jm","depends_on_id":"bd-280","type":"parent-child","created_at":"2026-02-25T06:57:38.292894Z","created_by":"themrb"},{"issue_id":"bd-3jm","depends_on_id":"bd-nn2","type":"blocks","created_at":"2026-02-25T07:00:26.623665Z","created_by":"themrb"}],"comments":[{"id":20,"issue_id":"bd-3jm","author":"HoangNB","text":"Goal:\nPrevent duplicate inflation while preserving traceability from normalized records back to source artifacts.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:38Z"}]}
{"id":"bd-3jn","title":"Implement representative sample extraction (default: 3 per source)","description":"Capture concise representative records for each source to aid debugging and adapter tuning.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:57:39.021734Z","created_by":"themrb","updated_at":"2026-02-25T07:00:27.279896Z","compaction_level":0,"original_size":0,"labels":["logit","samples","snapshot"],"dependencies":[{"issue_id":"bd-3jn","depends_on_id":"bd-39z","type":"parent-child","created_at":"2026-02-25T06:57:39.023344Z","created_by":"themrb"},{"issue_id":"bd-3jn","depends_on_id":"bd-jbe","type":"blocks","created_at":"2026-02-25T07:00:27.279881Z","created_by":"themrb"}],"comments":[{"id":32,"issue_id":"bd-3jn","author":"HoangNB","text":"Goal:\nCapture concise representative records for each source to aid debugging and adapter tuning.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:39Z"}]}
{"id":"bd-3kf","title":"Write troubleshooting and failure-mode cookbook","description":"Provide practical guidance for diagnosing parse failures, validation errors, and discovery gaps.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:57.681509Z","created_by":"themrb","updated_at":"2026-02-25T07:00:32.103109Z","compaction_level":0,"original_size":0,"labels":["docs","logit","operations"],"dependencies":[{"issue_id":"bd-3kf","depends_on_id":"bd-20c","type":"blocks","created_at":"2026-02-25T07:00:32.037041Z","created_by":"themrb"},{"issue_id":"bd-3kf","depends_on_id":"bd-241","type":"blocks","created_at":"2026-02-25T07:00:32.070650Z","created_by":"themrb"},{"issue_id":"bd-3kf","depends_on_id":"bd-5k4","type":"parent-child","created_at":"2026-02-25T06:58:57.682922Z","created_by":"themrb"},{"issue_id":"bd-3kf","depends_on_id":"bd-9rt","type":"blocks","created_at":"2026-02-25T07:00:32.103090Z","created_by":"themrb"}],"comments":[{"id":81,"issue_id":"bd-3kf","author":"HoangNB","text":"Goal:\nProvide practical guidance for diagnosing parse failures, validation errors, and discovery gaps.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:57Z"}]}
{"id":"bd-3l3","title":"Implement strict-mode thresholds and policy toggles","description":"Apply stricter null/error thresholds when strict mode is enabled and expose policy metadata.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:35.268675Z","created_by":"themrb","updated_at":"2026-02-25T07:00:30.725285Z","compaction_level":0,"original_size":0,"labels":["logit","subtask","validate"],"dependencies":[{"issue_id":"bd-3l3","depends_on_id":"bd-1ac","type":"blocks","created_at":"2026-02-25T07:00:30.725268Z","created_by":"themrb"},{"issue_id":"bd-3l3","depends_on_id":"bd-26k","type":"parent-child","created_at":"2026-02-25T06:59:35.270144Z","created_by":"themrb"}],"comments":[{"id":108,"issue_id":"bd-3l3","author":"HoangNB","text":"Subtask intent:\nApply stricter null/error thresholds when strict mode is enabled and expose policy metadata.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:35Z"}]}
{"id":"bd-3rs","title":"Flatten Amp typed parts into full text and excerpt","description":"Concatenate text-bearing parts deterministically for canonical text and excerpt fields.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:34.614581Z","created_by":"themrb","updated_at":"2026-02-25T06:59:34.649793Z","compaction_level":0,"original_size":0,"labels":["amp","logit","subtask"],"dependencies":[{"issue_id":"bd-3rs","depends_on_id":"bd-34x","type":"parent-child","created_at":"2026-02-25T06:59:34.616203Z","created_by":"themrb"}],"comments":[{"id":97,"issue_id":"bd-3rs","author":"HoangNB","text":"Subtask intent:\nConcatenate text-bearing parts deterministically for canonical text and excerpt fields.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:34Z"}]}
{"id":"bd-3t3","title":"Implement utility unit tests (time, hash, redaction, history parsing)","description":"Add deterministic unit tests for shared utility modules that underpin normalization correctness.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:57.186437Z","created_by":"themrb","updated_at":"2026-02-25T07:00:30.990089Z","compaction_level":0,"original_size":0,"labels":["logit","test","unit"],"dependencies":[{"issue_id":"bd-3t3","depends_on_id":"bd-13y","type":"parent-child","created_at":"2026-02-25T06:58:57.187975Z","created_by":"themrb"},{"issue_id":"bd-3t3","depends_on_id":"bd-1gt","type":"blocks","created_at":"2026-02-25T07:00:30.959248Z","created_by":"themrb"},{"issue_id":"bd-3t3","depends_on_id":"bd-1mo","type":"blocks","created_at":"2026-02-25T07:00:30.990072Z","created_by":"themrb"},{"issue_id":"bd-3t3","depends_on_id":"bd-386","type":"blocks","created_at":"2026-02-25T07:00:30.928927Z","created_by":"themrb"}],"comments":[{"id":73,"issue_id":"bd-3t3","author":"HoangNB","text":"Goal:\nAdd deterministic unit tests for shared utility modules that underpin normalization correctness.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:57Z"}]}
{"id":"bd-3ui","title":"Implement prioritization and filtering model (agent/source-kind/path)","description":"Allow deterministic ordering and targeted scans for focused runs and reproducibility.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:57:38.830009Z","created_by":"themrb","updated_at":"2026-02-25T07:00:27.150961Z","compaction_level":0,"original_size":0,"labels":["discovery","logit","priority"],"dependencies":[{"issue_id":"bd-3ui","depends_on_id":"bd-1re","type":"parent-child","created_at":"2026-02-25T06:57:38.831845Z","created_by":"themrb"},{"issue_id":"bd-3ui","depends_on_id":"bd-1w0","type":"blocks","created_at":"2026-02-25T07:00:27.083848Z","created_by":"themrb"},{"issue_id":"bd-3ui","depends_on_id":"bd-2lr","type":"blocks","created_at":"2026-02-25T07:00:27.117754Z","created_by":"themrb"},{"issue_id":"bd-3ui","depends_on_id":"bd-39f","type":"blocks","created_at":"2026-02-25T07:00:27.150946Z","created_by":"themrb"}],"comments":[{"id":29,"issue_id":"bd-3ui","author":"HoangNB","text":"Goal:\nAllow deterministic ordering and targeted scans for focused runs and reproducibility.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:38Z"}]}
{"id":"bd-3uo","title":"Claude adapter edge-case handling and mapping verification","description":"Consolidate Claude-specific event-shape variance and verify stable mapping across mixed record types.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:30.382730Z","created_by":"themrb","updated_at":"2026-02-25T07:00:28.651061Z","compaction_level":0,"original_size":0,"labels":["adapter","claude","logit","quality"],"dependencies":[{"issue_id":"bd-3uo","depends_on_id":"bd-2vc","type":"blocks","created_at":"2026-02-25T07:00:28.587425Z","created_by":"themrb"},{"issue_id":"bd-3uo","depends_on_id":"bd-fnj","type":"blocks","created_at":"2026-02-25T07:00:28.619296Z","created_by":"themrb"},{"issue_id":"bd-3uo","depends_on_id":"bd-l8n","type":"blocks","created_at":"2026-02-25T07:00:28.651029Z","created_by":"themrb"},{"issue_id":"bd-3uo","depends_on_id":"bd-lb0","type":"parent-child","created_at":"2026-02-25T06:58:30.384443Z","created_by":"themrb"}],"comments":[{"id":49,"issue_id":"bd-3uo","author":"HoangNB","text":"Goal:\nConsolidate Claude-specific event-shape variance and verify stable mapping across mixed record types.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-4t2","title":"Gemini adapter edge-case handling and mapping verification","description":"Consolidate Gemini nullability and sparse payload behaviors into explicit mapping and test expectations.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:30.614014Z","created_by":"themrb","updated_at":"2026-02-25T07:00:28.942217Z","compaction_level":0,"original_size":0,"labels":["adapter","gemini","logit","quality"],"dependencies":[{"issue_id":"bd-4t2","depends_on_id":"bd-12a","type":"blocks","created_at":"2026-02-25T07:00:28.942202Z","created_by":"themrb"},{"issue_id":"bd-4t2","depends_on_id":"bd-1k0","type":"blocks","created_at":"2026-02-25T07:00:28.909300Z","created_by":"themrb"},{"issue_id":"bd-4t2","depends_on_id":"bd-38g","type":"parent-child","created_at":"2026-02-25T06:58:30.616069Z","created_by":"themrb"},{"issue_id":"bd-4t2","depends_on_id":"bd-9yb","type":"blocks","created_at":"2026-02-25T07:00:28.876070Z","created_by":"themrb"}],"comments":[{"id":53,"issue_id":"bd-4t2","author":"HoangNB","text":"Goal:\nConsolidate Gemini nullability and sparse payload behaviors into explicit mapping and test expectations.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-5k4","title":"Epic: Documentation, Operational Guidance, and Release Readiness","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-25T06:56:29.577684Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.474277Z","compaction_level":0,"original_size":0,"labels":["docs","epic","logit"],"dependencies":[{"issue_id":"bd-5k4","depends_on_id":"bd-13y","type":"blocks","created_at":"2026-02-25T07:00:26.474261Z","created_by":"themrb"},{"issue_id":"bd-5k4","depends_on_id":"bd-1d7","type":"parent-child","created_at":"2026-02-25T06:56:29.578911Z","created_by":"themrb"}],"comments":[{"id":15,"issue_id":"bd-5k4","author":"HoangNB","text":"Intent:\nMake the project operable by future contributors without oral context.\n\nScope:\n- architecture, command usage, safety notes\n- troubleshooting and known limitations\n- release checklist and acceptance evidence map\n","created_at":"2026-02-25T06:56:30Z"}]}
{"id":"bd-8o6","title":"Write release checklist and acceptance evidence template","description":"Define a repeatable release readiness checklist and evidence template tied to acceptance criteria.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:57.744217Z","created_by":"themrb","updated_at":"2026-02-25T07:00:32.307461Z","compaction_level":0,"original_size":0,"labels":["docs","logit","release"],"dependencies":[{"issue_id":"bd-8o6","depends_on_id":"bd-21o","type":"blocks","created_at":"2026-02-25T07:00:32.177067Z","created_by":"themrb"},{"issue_id":"bd-8o6","depends_on_id":"bd-2tt","type":"blocks","created_at":"2026-02-25T07:00:32.275359Z","created_by":"themrb"},{"issue_id":"bd-8o6","depends_on_id":"bd-3ck","type":"blocks","created_at":"2026-02-25T07:00:32.138933Z","created_by":"themrb"},{"issue_id":"bd-8o6","depends_on_id":"bd-3kf","type":"blocks","created_at":"2026-02-25T07:00:32.307444Z","created_by":"themrb"},{"issue_id":"bd-8o6","depends_on_id":"bd-5k4","type":"parent-child","created_at":"2026-02-25T06:58:57.745709Z","created_by":"themrb"},{"issue_id":"bd-8o6","depends_on_id":"bd-ty9","type":"blocks","created_at":"2026-02-25T07:00:32.209234Z","created_by":"themrb"},{"issue_id":"bd-8o6","depends_on_id":"bd-ubx","type":"blocks","created_at":"2026-02-25T07:00:32.243511Z","created_by":"themrb"}],"comments":[{"id":82,"issue_id":"bd-8o6","author":"HoangNB","text":"Goal:\nDefine a repeatable release readiness checklist and evidence template tied to acceptance criteria.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:57Z"}]}
{"id":"bd-8vn","title":"Author per-agent discovery path table with precedence rules","description":"Define ordered path candidates per agent and precedence for conflicting discoveries.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:33.948606Z","created_by":"themrb","updated_at":"2026-02-25T06:59:33.985106Z","compaction_level":0,"original_size":0,"labels":["discovery","logit","subtask"],"dependencies":[{"issue_id":"bd-8vn","depends_on_id":"bd-1w0","type":"parent-child","created_at":"2026-02-25T06:59:33.949919Z","created_by":"themrb"}],"comments":[{"id":87,"issue_id":"bd-8vn","author":"HoangNB","text":"Subtask intent:\nDefine ordered path candidates per agent and precedence for conflicting discoveries.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:33Z"}]}
{"id":"bd-9bi","title":"Map Codex response_item payload variants to canonical content","description":"Handle message payload variants and preserve role/content/provenance accurately.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:34.245771Z","created_by":"themrb","updated_at":"2026-02-25T06:59:34.282455Z","compaction_level":0,"original_size":0,"labels":["codex","logit","subtask"],"dependencies":[{"issue_id":"bd-9bi","depends_on_id":"bd-2j8","type":"parent-child","created_at":"2026-02-25T06:59:34.247692Z","created_by":"themrb"}],"comments":[{"id":91,"issue_id":"bd-9bi","author":"HoangNB","text":"Subtask intent:\nHandle message payload variants and preserve role/content/provenance accurately.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:34Z"}]}
{"id":"bd-9eb","title":"Implement normalize orchestrator that fans in all adapters","description":"Coordinate adapter execution, normalization, and artifact emission in one deterministic command path.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:39.546197Z","created_by":"themrb","updated_at":"2026-02-25T07:00:30.079792Z","compaction_level":0,"original_size":0,"labels":["logit","normalize","orchestration"],"dependencies":[{"issue_id":"bd-9eb","depends_on_id":"bd-165","type":"parent-child","created_at":"2026-02-25T06:57:39.547469Z","created_by":"themrb"},{"issue_id":"bd-9eb","depends_on_id":"bd-182","type":"blocks","created_at":"2026-02-25T07:00:27.908769Z","created_by":"themrb"},{"issue_id":"bd-9eb","depends_on_id":"bd-1a1","type":"blocks","created_at":"2026-02-25T07:00:30.006254Z","created_by":"themrb"},{"issue_id":"bd-9eb","depends_on_id":"bd-1ly","type":"blocks","created_at":"2026-02-25T07:00:28.007158Z","created_by":"themrb"},{"issue_id":"bd-9eb","depends_on_id":"bd-2uh","type":"blocks","created_at":"2026-02-25T07:00:28.074894Z","created_by":"themrb"},{"issue_id":"bd-9eb","depends_on_id":"bd-2x6","type":"blocks","created_at":"2026-02-25T07:00:27.973370Z","created_by":"themrb"},{"issue_id":"bd-9eb","depends_on_id":"bd-2yx","type":"blocks","created_at":"2026-02-25T07:00:30.048173Z","created_by":"themrb"},{"issue_id":"bd-9eb","depends_on_id":"bd-343","type":"blocks","created_at":"2026-02-25T07:00:27.940692Z","created_by":"themrb"},{"issue_id":"bd-9eb","depends_on_id":"bd-3i0","type":"blocks","created_at":"2026-02-25T07:00:27.877251Z","created_by":"themrb"},{"issue_id":"bd-9eb","depends_on_id":"bd-3ui","type":"blocks","created_at":"2026-02-25T07:00:30.079775Z","created_by":"themrb"},{"issue_id":"bd-9eb","depends_on_id":"bd-3uo","type":"blocks","created_at":"2026-02-25T07:00:29.876997Z","created_by":"themrb"},{"issue_id":"bd-9eb","depends_on_id":"bd-4t2","type":"blocks","created_at":"2026-02-25T07:00:29.929179Z","created_by":"themrb"},{"issue_id":"bd-9eb","depends_on_id":"bd-9ej","type":"blocks","created_at":"2026-02-25T07:00:28.041143Z","created_by":"themrb"},{"issue_id":"bd-9eb","depends_on_id":"bd-fqr","type":"blocks","created_at":"2026-02-25T07:00:29.842534Z","created_by":"themrb"}],"comments":[{"id":41,"issue_id":"bd-9eb","author":"HoangNB","text":"Goal:\nCoordinate adapter execution, normalization, and artifact emission in one deterministic command path.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:39Z"}]}
{"id":"bd-9ej","title":"Implement dedupe engine and stable global event ordering","description":"Guarantee consistent event stream generation without duplicate inflation or nondeterministic ordering.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:39.434290Z","created_by":"themrb","updated_at":"2026-02-25T07:00:27.786454Z","compaction_level":0,"original_size":0,"labels":["dedupe","logit","normalize"],"dependencies":[{"issue_id":"bd-9ej","depends_on_id":"bd-165","type":"parent-child","created_at":"2026-02-25T06:57:39.435655Z","created_by":"themrb"},{"issue_id":"bd-9ej","depends_on_id":"bd-1ly","type":"blocks","created_at":"2026-02-25T07:00:27.786439Z","created_by":"themrb"},{"issue_id":"bd-9ej","depends_on_id":"bd-2x6","type":"blocks","created_at":"2026-02-25T07:00:27.755589Z","created_by":"themrb"},{"issue_id":"bd-9ej","depends_on_id":"bd-3jm","type":"blocks","created_at":"2026-02-25T07:00:27.723929Z","created_by":"themrb"}],"comments":[{"id":39,"issue_id":"bd-9ej","author":"HoangNB","text":"Goal:\nGuarantee consistent event stream generation without duplicate inflation or nondeterministic ordering.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:39Z"}]}
{"id":"bd-9rt","title":"Implement local environment smoke tests for discovery and adapter coverage","description":"Add smoke checks that ensure discovery and normalization can run on realistic local directory structures.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:57.369851Z","created_by":"themrb","updated_at":"2026-02-25T07:00:31.399326Z","compaction_level":0,"original_size":0,"labels":["logit","smoke","test"],"dependencies":[{"issue_id":"bd-9rt","depends_on_id":"bd-13y","type":"parent-child","created_at":"2026-02-25T06:58:57.371286Z","created_by":"themrb"},{"issue_id":"bd-9rt","depends_on_id":"bd-1dk","type":"blocks","created_at":"2026-02-25T07:00:31.369056Z","created_by":"themrb"},{"issue_id":"bd-9rt","depends_on_id":"bd-9eb","type":"blocks","created_at":"2026-02-25T07:00:31.399309Z","created_by":"themrb"}],"comments":[{"id":76,"issue_id":"bd-9rt","author":"HoangNB","text":"Goal:\nAdd smoke checks that ensure discovery and normalization can run on realistic local directory structures.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:57Z"}]}
{"id":"bd-9yb","title":"Parse Gemini tmp logs.json arrays (including empty-array cases)","description":"Handle Gemini logs.json array payloads robustly, including empty arrays and sparse message entries.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:30.439706Z","created_by":"themrb","updated_at":"2026-02-25T07:00:28.779617Z","compaction_level":0,"original_size":0,"labels":["adapter","gemini","logit","logs"],"dependencies":[{"issue_id":"bd-9yb","depends_on_id":"bd-1ly","type":"blocks","created_at":"2026-02-25T07:00:28.779602Z","created_by":"themrb"},{"issue_id":"bd-9yb","depends_on_id":"bd-343","type":"blocks","created_at":"2026-02-25T07:00:28.742598Z","created_by":"themrb"},{"issue_id":"bd-9yb","depends_on_id":"bd-38g","type":"parent-child","created_at":"2026-02-25T06:58:30.441605Z","created_by":"themrb"}],"comments":[{"id":50,"issue_id":"bd-9yb","author":"HoangNB","text":"Goal:\nHandle Gemini logs.json array payloads robustly, including empty arrays and sparse message entries.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-asg","title":"Implement adapter fan-in execution plan and failure isolation","description":"Define adapter execution ordering and isolate adapter failures from global command crashes.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:34.988171Z","created_by":"themrb","updated_at":"2026-02-25T06:59:35.023044Z","compaction_level":0,"original_size":0,"labels":["logit","normalize","subtask"],"dependencies":[{"issue_id":"bd-asg","depends_on_id":"bd-9eb","type":"parent-child","created_at":"2026-02-25T06:59:34.990061Z","created_by":"themrb"}],"comments":[{"id":103,"issue_id":"bd-asg","author":"HoangNB","text":"Subtask intent:\nDefine adapter execution ordering and isolate adapter failures from global command crashes.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:35Z"}]}
{"id":"bd-cwf","title":"Preserve non-text Amp parts in structured content_parts","description":"Retain non-text structured parts without lossy conversion to maintain fidelity.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:34.675279Z","created_by":"themrb","updated_at":"2026-02-25T07:00:29.430649Z","compaction_level":0,"original_size":0,"labels":["amp","logit","subtask"],"dependencies":[{"issue_id":"bd-cwf","depends_on_id":"bd-34x","type":"parent-child","created_at":"2026-02-25T06:59:34.677603Z","created_by":"themrb"},{"issue_id":"bd-cwf","depends_on_id":"bd-3rs","type":"blocks","created_at":"2026-02-25T07:00:29.430634Z","created_by":"themrb"}],"comments":[{"id":98,"issue_id":"bd-cwf","author":"HoangNB","text":"Subtask intent:\nRetain non-text structured parts without lossy conversion to maintain fidelity.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:34Z"}]}
{"id":"bd-fnj","title":"Parse Claude subagent session traces with explicit tagging","description":"Ingest Claude subagent traces and tag them so downstream analysis can separate primary and delegated activity.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:30.273251Z","created_by":"themrb","updated_at":"2026-02-25T07:00:28.527988Z","compaction_level":0,"original_size":0,"labels":["adapter","claude","logit","subagent"],"dependencies":[{"issue_id":"bd-fnj","depends_on_id":"bd-2vc","type":"blocks","created_at":"2026-02-25T07:00:28.527973Z","created_by":"themrb"},{"issue_id":"bd-fnj","depends_on_id":"bd-lb0","type":"parent-child","created_at":"2026-02-25T06:58:30.274739Z","created_by":"themrb"}],"comments":[{"id":47,"issue_id":"bd-fnj","author":"HoangNB","text":"Goal:\nIngest Claude subagent traces and tag them so downstream analysis can separate primary and delegated activity.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-fqr","title":"Codex adapter edge-case handling and mapping verification","description":"Consolidate Codex-specific null handling, unknown event-kind fallbacks, and verification cases.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:30.158488Z","created_by":"themrb","updated_at":"2026-02-25T07:00:28.369066Z","compaction_level":0,"original_size":0,"labels":["adapter","codex","logit","quality"],"dependencies":[{"issue_id":"bd-fqr","depends_on_id":"bd-10m","type":"blocks","created_at":"2026-02-25T07:00:28.336127Z","created_by":"themrb"},{"issue_id":"bd-fqr","depends_on_id":"bd-2j8","type":"blocks","created_at":"2026-02-25T07:00:28.303326Z","created_by":"themrb"},{"issue_id":"bd-fqr","depends_on_id":"bd-398","type":"parent-child","created_at":"2026-02-25T06:58:30.160302Z","created_by":"themrb"},{"issue_id":"bd-fqr","depends_on_id":"bd-smr","type":"blocks","created_at":"2026-02-25T07:00:28.369051Z","created_by":"themrb"}],"comments":[{"id":45,"issue_id":"bd-fqr","author":"HoangNB","text":"Goal:\nConsolidate Codex-specific null handling, unknown event-kind fallbacks, and verification cases.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-fxn","title":"Implement truncation and binary-safe sample sanitization","description":"Enforce bounded sample sizes and safe handling for binary or extremely large fields.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:34.177027Z","created_by":"themrb","updated_at":"2026-02-25T07:00:27.523341Z","compaction_level":0,"original_size":0,"labels":["logit","snapshot","subtask"],"dependencies":[{"issue_id":"bd-fxn","depends_on_id":"bd-29m","type":"blocks","created_at":"2026-02-25T07:00:27.523326Z","created_by":"themrb"},{"issue_id":"bd-fxn","depends_on_id":"bd-3ew","type":"parent-child","created_at":"2026-02-25T06:59:34.185043Z","created_by":"themrb"}],"comments":[{"id":90,"issue_id":"bd-fxn","author":"HoangNB","text":"Subtask intent:\nEnforce bounded sample sizes and safe handling for binary or extremely large fields.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:34Z"}]}
{"id":"bd-if6","title":"Add normalize workflow golden artifact tests","description":"Verify normalize command produces stable artifact structure and schema-compliant events.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:35.459464Z","created_by":"themrb","updated_at":"2026-02-25T06:59:35.500709Z","compaction_level":0,"original_size":0,"labels":["logit","subtask","test"],"dependencies":[{"issue_id":"bd-if6","depends_on_id":"bd-241","type":"parent-child","created_at":"2026-02-25T06:59:35.461086Z","created_by":"themrb"}],"comments":[{"id":111,"issue_id":"bd-if6","author":"HoangNB","text":"Subtask intent:\nVerify normalize command produces stable artifact structure and schema-compliant events.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:35Z"}]}
{"id":"bd-jbe","title":"Implement per-source schema/key profiler and event-kind frequency analyzer","description":"Extract structural signatures from sources to monitor parser assumptions and drift.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:38.968676Z","created_by":"themrb","updated_at":"2026-02-25T07:00:27.250140Z","compaction_level":0,"original_size":0,"labels":["logit","profiling","snapshot"],"dependencies":[{"issue_id":"bd-jbe","depends_on_id":"bd-2lr","type":"blocks","created_at":"2026-02-25T07:00:27.250125Z","created_by":"themrb"},{"issue_id":"bd-jbe","depends_on_id":"bd-39z","type":"parent-child","created_at":"2026-02-25T06:57:38.970077Z","created_by":"themrb"}],"comments":[{"id":31,"issue_id":"bd-jbe","author":"HoangNB","text":"Goal:\nExtract structural signatures from sources to monitor parser assumptions and drift.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:39Z"}]}
{"id":"bd-l8n","title":"Parse Claude history and MCP cache logs as auxiliary sources","description":"Capture Claude history plus mcp cache debug logs with clear source-kind labels and non-conversational typing where appropriate.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:30.327647Z","created_by":"themrb","updated_at":"2026-02-25T07:00:28.558243Z","compaction_level":0,"original_size":0,"labels":["adapter","aux","claude","logit"],"dependencies":[{"issue_id":"bd-l8n","depends_on_id":"bd-2vc","type":"blocks","created_at":"2026-02-25T07:00:28.558228Z","created_by":"themrb"},{"issue_id":"bd-l8n","depends_on_id":"bd-lb0","type":"parent-child","created_at":"2026-02-25T06:58:30.329341Z","created_by":"themrb"}],"comments":[{"id":48,"issue_id":"bd-l8n","author":"HoangNB","text":"Goal:\nCapture Claude history plus mcp cache debug logs with clear source-kind labels and non-conversational typing where appropriate.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-lb0","title":"Epic: Claude Adapter","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-25T06:56:29.311322Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.039970Z","compaction_level":0,"original_size":0,"labels":["adapter","claude","epic","logit"],"dependencies":[{"issue_id":"bd-lb0","depends_on_id":"bd-1d7","type":"parent-child","created_at":"2026-02-25T06:56:29.312933Z","created_by":"themrb"},{"issue_id":"bd-lb0","depends_on_id":"bd-280","type":"blocks","created_at":"2026-02-25T07:00:26.039954Z","created_by":"themrb"}],"comments":[{"id":7,"issue_id":"bd-lb0","author":"HoangNB","text":"Intent:\nNormalize Claude project/session artifacts including primary and subagent traces.\n\nConsiderations:\n- heterogeneous event kinds (`user`, `assistant`, `progress`, etc.)\n- mcp cache logs are diagnostic not conversational\n- maintain source tags for downstream filtering\n","created_at":"2026-02-25T06:56:29Z"}]}
{"id":"bd-lq8","title":"Add malformed-record regression tests per adapter","description":"Ensure malformed source records are handled gracefully and consistently.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:35.392997Z","created_by":"themrb","updated_at":"2026-02-25T07:00:31.599816Z","compaction_level":0,"original_size":0,"labels":["logit","subtask","test"],"dependencies":[{"issue_id":"bd-lq8","depends_on_id":"bd-2il","type":"parent-child","created_at":"2026-02-25T06:59:35.394469Z","created_by":"themrb"},{"issue_id":"bd-lq8","depends_on_id":"bd-2o7","type":"blocks","created_at":"2026-02-25T07:00:31.599798Z","created_by":"themrb"}],"comments":[{"id":110,"issue_id":"bd-lq8","author":"HoangNB","text":"Subtask intent:\nEnsure malformed source records are handled gracefully and consistently.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:35Z"}]}
{"id":"bd-mt5","title":"Implement record-count parity checker between JSONL and SQLite","description":"Verify mirrored output count parity and surface mismatches with actionable diagnostics.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:35.107026Z","created_by":"themrb","updated_at":"2026-02-25T06:59:35.138939Z","compaction_level":0,"original_size":0,"labels":["logit","sqlite","subtask"],"dependencies":[{"issue_id":"bd-mt5","depends_on_id":"bd-ohq","type":"parent-child","created_at":"2026-02-25T06:59:35.108524Z","created_by":"themrb"}],"comments":[{"id":105,"issue_id":"bd-mt5","author":"HoangNB","text":"Subtask intent:\nVerify mirrored output count parity and surface mismatches with actionable diagnostics.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:35Z"}]}
{"id":"bd-nn2","title":"Define canonical agentlog.v1 field semantics and invariants","description":"Codify the meaning, optionality, and allowed values of every normalized field so adapters and validators cannot diverge.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:57:38.051812Z","created_by":"themrb","updated_at":"2026-02-25T06:58:29.660239Z","compaction_level":0,"original_size":0,"labels":["architecture","contract","logit"],"dependencies":[{"issue_id":"bd-nn2","depends_on_id":"bd-280","type":"parent-child","created_at":"2026-02-25T06:57:38.054375Z","created_by":"themrb"}],"comments":[{"id":16,"issue_id":"bd-nn2","author":"HoangNB","text":"Goal:\nCodify the meaning, optionality, and allowed values of every normalized field so adapters and validators cannot diverge.\n\nBackground / reasoning:\nThis task exists to make the  pipeline deterministic, auditable, and maintainable over time.\nThe deliverable should avoid hidden assumptions and make behavior explicit for future contributors.\n\nImplementation notes:\n- Prefer pure functions and explicit data contracts.\n- Preserve provenance metadata to support debugging.\n- Keep output stable to avoid flaky downstream tooling.\n\nDefinition of done:\n- Behavior is implemented and testable.\n- Edge cases relevant to this scope are handled or explicitly documented.\n- Task output is consumable by dependent tasks without reinterpretation.\n","created_at":"2026-02-25T06:57:38Z"}]}
{"id":"bd-ohq","title":"Implement parity checks between JSONL and SQLite mirror outputs","description":"Verify mirror integrity by comparing record counts and critical fields between JSONL and SQLite outputs.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:56.854537Z","created_by":"themrb","updated_at":"2026-02-25T07:00:30.316972Z","compaction_level":0,"original_size":0,"labels":["logit","parity","sqlite"],"dependencies":[{"issue_id":"bd-ohq","depends_on_id":"bd-10h","type":"blocks","created_at":"2026-02-25T07:00:30.283684Z","created_by":"themrb"},{"issue_id":"bd-ohq","depends_on_id":"bd-1kq","type":"parent-child","created_at":"2026-02-25T06:58:56.856007Z","created_by":"themrb"},{"issue_id":"bd-ohq","depends_on_id":"bd-2uh","type":"blocks","created_at":"2026-02-25T07:00:30.316956Z","created_by":"themrb"}],"comments":[{"id":67,"issue_id":"bd-ohq","author":"HoangNB","text":"Goal:\nVerify mirror integrity by comparing record counts and critical fields between JSONL and SQLite outputs.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:56Z"}]}
{"id":"bd-qug","title":"Draft acceptance evidence template for future implementation runs","description":"Create evidence-capture template for proving each acceptance criterion is satisfied.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:35.716293Z","created_by":"themrb","updated_at":"2026-02-25T07:00:32.370891Z","compaction_level":0,"original_size":0,"labels":["docs","logit","subtask"],"dependencies":[{"issue_id":"bd-qug","depends_on_id":"bd-1fy","type":"blocks","created_at":"2026-02-25T07:00:32.370851Z","created_by":"themrb"},{"issue_id":"bd-qug","depends_on_id":"bd-8o6","type":"parent-child","created_at":"2026-02-25T06:59:35.718076Z","created_by":"themrb"}],"comments":[{"id":114,"issue_id":"bd-qug","author":"HoangNB","text":"Subtask intent:\nCreate evidence-capture template for proving each acceptance criterion is satisfied.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:35Z"}]}
{"id":"bd-smr","title":"Parse Codex TUI and desktop logs as diagnostic events","description":"Capture Codex runtime logs as tagged diagnostic events for troubleshooting without conflating them with chat content.","status":"open","priority":3,"issue_type":"task","created_at":"2026-02-25T06:58:30.099852Z","created_by":"themrb","updated_at":"2026-02-25T07:00:28.270943Z","compaction_level":0,"original_size":0,"labels":["adapter","codex","logit","logs"],"dependencies":[{"issue_id":"bd-smr","depends_on_id":"bd-2j8","type":"blocks","created_at":"2026-02-25T07:00:28.270928Z","created_by":"themrb"},{"issue_id":"bd-smr","depends_on_id":"bd-398","type":"parent-child","created_at":"2026-02-25T06:58:30.101302Z","created_by":"themrb"}],"comments":[{"id":44,"issue_id":"bd-smr","author":"HoangNB","text":"Goal:\nCapture Codex runtime logs as tagged diagnostic events for troubleshooting without conflating them with chat content.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:30Z"}]}
{"id":"bd-soe","title":"Epic: CLI Skeleton, Command Surface, and Runtime Plumbing","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-25T06:56:29.174448Z","created_by":"themrb","updated_at":"2026-02-25T06:56:29.658971Z","compaction_level":0,"original_size":0,"labels":["cli","epic","logit"],"dependencies":[{"issue_id":"bd-soe","depends_on_id":"bd-1d7","type":"parent-child","created_at":"2026-02-25T06:56:29.175542Z","created_by":"themrb"}],"comments":[{"id":3,"issue_id":"bd-soe","author":"HoangNB","text":"Intent:\nCreate a robust Rust CLI shell that supports command growth without command-sprawl.\n\nScope:\n- `snapshot`, `normalize`, `inspect`, `validate` command family\n- global flags and predictable error model\n- filesystem-safe runtime behavior and clear exit codes\n\nDesign principle:\nThe command interface is part of the public API and must stay stable once published.\n","created_at":"2026-02-25T06:56:29Z"}]}
{"id":"bd-ty9","title":"Write README quickstart and command usage guide","description":"Document installation assumptions, command usage patterns, and primary workflows for first-time contributors.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:57.482953Z","created_by":"themrb","updated_at":"2026-02-25T07:00:31.764964Z","compaction_level":0,"original_size":0,"labels":["docs","logit","readme"],"dependencies":[{"issue_id":"bd-ty9","depends_on_id":"bd-3i0","type":"blocks","created_at":"2026-02-25T07:00:31.730447Z","created_by":"themrb"},{"issue_id":"bd-ty9","depends_on_id":"bd-5k4","type":"parent-child","created_at":"2026-02-25T06:58:57.484418Z","created_by":"themrb"},{"issue_id":"bd-ty9","depends_on_id":"bd-9eb","type":"blocks","created_at":"2026-02-25T07:00:31.764948Z","created_by":"themrb"}],"comments":[{"id":78,"issue_id":"bd-ty9","author":"HoangNB","text":"Goal:\nDocument installation assumptions, command usage patterns, and primary workflows for first-time contributors.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:57Z"}]}
{"id":"bd-u6d","title":"Epic: Validation and Consistency Reports","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-25T06:56:29.512433Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.199784Z","compaction_level":0,"original_size":0,"labels":["epic","logit","validate"],"dependencies":[{"issue_id":"bd-u6d","depends_on_id":"bd-165","type":"blocks","created_at":"2026-02-25T07:00:26.199765Z","created_by":"themrb"},{"issue_id":"bd-u6d","depends_on_id":"bd-1d7","type":"parent-child","created_at":"2026-02-25T06:56:29.513645Z","created_by":"themrb"}],"comments":[{"id":13,"issue_id":"bd-u6d","author":"HoangNB","text":"Intent:\nShip a strict but practical validation layer that certifies normalized outputs.\n\nScope:\n- schema validation\n- invariant checks (required keys, timestamp sanity)\n- machine-readable validation report and exit codes\n","created_at":"2026-02-25T06:56:30Z"}]}
{"id":"bd-ubx","title":"Write architecture and data model documentation","description":"Document internal module boundaries, adapter strategy, and canonical data model rationale.","status":"open","priority":1,"issue_type":"task","created_at":"2026-02-25T06:58:57.549088Z","created_by":"themrb","updated_at":"2026-02-25T07:00:31.901177Z","compaction_level":0,"original_size":0,"labels":["architecture","docs","logit"],"dependencies":[{"issue_id":"bd-ubx","depends_on_id":"bd-2n2","type":"blocks","created_at":"2026-02-25T07:00:31.834689Z","created_by":"themrb"},{"issue_id":"bd-ubx","depends_on_id":"bd-343","type":"blocks","created_at":"2026-02-25T07:00:31.867788Z","created_by":"themrb"},{"issue_id":"bd-ubx","depends_on_id":"bd-5k4","type":"parent-child","created_at":"2026-02-25T06:58:57.550257Z","created_by":"themrb"},{"issue_id":"bd-ubx","depends_on_id":"bd-9eb","type":"blocks","created_at":"2026-02-25T07:00:31.901158Z","created_by":"themrb"},{"issue_id":"bd-ubx","depends_on_id":"bd-nn2","type":"blocks","created_at":"2026-02-25T07:00:31.801406Z","created_by":"themrb"}],"comments":[{"id":79,"issue_id":"bd-ubx","author":"HoangNB","text":"Goal:\nDocument internal module boundaries, adapter strategy, and canonical data model rationale.\n\nBackground / reasoning:\nThis work item closes a quality, operability, or maintainability gap needed for production-grade local tooling.\n\nImplementation notes:\n- Keep behavior deterministic and observable.\n- Prefer explicit failure reporting over silent fallback.\n- Preserve parity with canonical event semantics.\n\nDefinition of done:\n- Output is reproducible and documented.\n- Validation and/or tests exist for core behavior.\n- Dependent tasks can proceed without hidden assumptions.\n","created_at":"2026-02-25T06:58:57Z"}]}
{"id":"bd-xdl","title":"Epic: OpenCode Adapter","status":"open","priority":1,"issue_type":"epic","created_at":"2026-02-25T06:56:29.420621Z","created_by":"themrb","updated_at":"2026-02-25T07:00:26.109860Z","compaction_level":0,"original_size":0,"labels":["adapter","epic","logit","opencode"],"dependencies":[{"issue_id":"bd-xdl","depends_on_id":"bd-1d7","type":"parent-child","created_at":"2026-02-25T06:56:29.421920Z","created_by":"themrb"},{"issue_id":"bd-xdl","depends_on_id":"bd-280","type":"blocks","created_at":"2026-02-25T07:00:26.109844Z","created_by":"themrb"}],"comments":[{"id":10,"issue_id":"bd-xdl","author":"HoangNB","text":"Intent:\nNormalize OpenCode by joining session message metadata with session part payloads.\n\nConsiderations:\n- content frequently resides in part records, not message rows\n- require reliable join keys (`messageID`, `sessionID`)\n- preserve provider/model/cost metadata where available\n","created_at":"2026-02-25T06:56:29Z"}]}
{"id":"bd-xok","title":"Implement stable sort comparator for mixed timestamp quality","description":"Order events deterministically when timestamps are null, malformed, or equal.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:59:34.931675Z","created_by":"themrb","updated_at":"2026-02-25T07:00:28.107493Z","compaction_level":0,"original_size":0,"labels":["logit","normalize","subtask"],"dependencies":[{"issue_id":"bd-xok","depends_on_id":"bd-1oy","type":"blocks","created_at":"2026-02-25T07:00:28.107476Z","created_by":"themrb"},{"issue_id":"bd-xok","depends_on_id":"bd-9ej","type":"parent-child","created_at":"2026-02-25T06:59:34.933357Z","created_by":"themrb"}],"comments":[{"id":102,"issue_id":"bd-xok","author":"HoangNB","text":"Subtask intent:\nOrder events deterministically when timestamps are null, malformed, or equal.\n\nWhy now:\nBreaking this parent task into explicit sub-steps reduces ambiguity and supports parallel execution without semantic drift.\n\nDone when:\n- Sub-step output is complete and reviewable.\n- Parent task can consume this output directly.\n","created_at":"2026-02-25T06:59:34Z"}]}
{"id":"bd-yr2","title":"Parse OpenCode runtime logs and prompt history as auxiliary sources","description":"Capture OpenCode runtime logs and prompt-history artifacts with appropriate event typing and tags.","status":"open","priority":2,"issue_type":"task","created_at":"2026-02-25T06:58:31.128436Z","created_by":"themrb","updated_at":"2026-02-25T07:00:29.632122Z","compaction_level":0,"original_size":0,"labels":["adapter","aux","logit","opencode"],"dependencies":[{"issue_id":"bd-yr2","depends_on_id":"bd-28v","type":"blocks","created_at":"2026-02-25T07:00:29.632106Z","created_by":"themrb"},{"issue_id":"bd-yr2","depends_on_id":"bd-xdl","type":"parent-child","created_at":"2026-02-25T06:58:31.130537Z","created_by":"themrb"}],"comments":[{"id":62,"issue_id":"bd-yr2","author":"HoangNB","text":"Goal:\nCapture OpenCode runtime logs and prompt-history artifacts with appropriate event typing and tags.\n\nBackground / reasoning:\nThis task captures source-specific behavior that must be preserved while translating into the common event model.\nAccuracy matters more than cleverness; normalize conservatively and preserve provenance.\n\nImplementation notes:\n- Document assumptions discovered in real local files.\n- Handle malformed or partial records without crashing full runs.\n- Tag diagnostic-only sources distinctly from conversational records.\n\nDefinition of done:\n- Parsing/mapping behavior is implemented for the scoped source shapes.\n- Output aligns with canonical normalization semantics.\n- Error handling paths are explicit and testable.\n","created_at":"2026-02-25T06:58:31Z"}]}
